"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[3518],{4369:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/helllo_world","metadata":{"permalink":"/helllo_world","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/helllo_world.md","source":"@site/blog/helllo_world.md","title":"Hello World!","description":"Hello !","date":"2024-12-28T12:04:31.000Z","tags":[],"readingTime":0.05,"hasTruncateMarker":false,"authors":[],"frontMatter":{"layout":"post","title":"Hello World!","category":"work"},"unlisted":false,"nextItem":{"title":"Setup Prometheus on private k8s cluster","permalink":"/2024/12/18/forth-prometheus"}},"content":"Hello !\\n\\n\uc5b4\uc81c(24.12.28) \ub9cc\ub4e4\uc5c8\ub124\uc694"},{"id":"/2024/12/18/forth-prometheus","metadata":{"permalink":"/2024/12/18/forth-prometheus","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2024-12-18-forth-prometheus.md","source":"@site/blog/2024-12-18-forth-prometheus.md","title":"Setup Prometheus on private k8s cluster","description":"summary","date":"2024-12-17T16:16:01.000Z","tags":[{"inline":true,"label":"Observability","permalink":"/tags/observability"},{"inline":true,"label":"Prometheus","permalink":"/tags/prometheus"},{"inline":true,"label":"Loki","permalink":"/tags/loki"},{"inline":true,"label":"Tempo","permalink":"/tags/tempo"},{"inline":true,"label":"Opentelemetry auto-instrument","permalink":"/tags/opentelemetry-auto-instrument"}],"readingTime":11.37,"hasTruncateMarker":true,"authors":[{"name":"Hanbyul Cho","title":"Engineer","url":"https://github.com/hansgun","page":{"permalink":"/authors/hansgun"},"socials":{"linkedin":"https://www.linkedin.com/in/hanbyulcho1/","github":"https://github.com/hansgun"},"imageURL":"https://github.com/hansgun.png","key":"hansgun"}],"frontMatter":{"layout":"single","title":"Setup Prometheus on private k8s cluster","date":"2024-12-17 16:16:01 -0600","categories":"work","tags":["Observability","Prometheus","Loki","Tempo","Opentelemetry auto-instrument"],"author_profile":false,"toc":true,"toc_label":"On This Page","toc_icon":"cog","toc_position":"sticky","authors":["hansgun"]},"unlisted":false,"prevItem":{"title":"Hello World!","permalink":"/helllo_world"},"nextItem":{"title":"Redis A-S(Active-Standby/Master-Slave) cluster \uad6c\ucd95\uae30","permalink":"/2024/11/01/fifth-Redis-cluster"}},"content":"> summary\\n\x3c!-- truncate --\x3e\\n# Prolog \\n- \uc0c1\uc6a9 SaaS Observability \ud234\uc740 modern\ud55c \uadf8\ub798\ud53d\uacfc \ud3b8\uc758\uc131\uc744 \uc81c\uacf5\ud558\uc9c0\ub9cc(ex:Datadog), \uc0ac\uc6a9\ub7c9 base\ub85c \uacfc\uae08\uc73c\ub85c \ucd5c\uc801\ud654 \ud558\uc9c0 \uc54a\uc740 Log, Trace \ud639\uc740 Profile \uae30\ub2a5\uc744 \ud65c\uc6a9 \uc2dc \uacfc\uae08 \ud3ed\ud0c4\uc744 \ub9de\uace0 \uc788\ub2e4. \\n- Open Source \uc774\uc790, k8s \ud658\uacbd\uc5d0 \uc798 \uc801\uc6a9\ub418\uace0, \ube60\ub974\uac8c \ubc1c\uc804\uc911\uc778 Prometheus\ub85c \ub300\uccb4 \ud558\uace0\uc790 \ud604 \uc6b4\uc601\uc911\uc778 private k8s cluster\uc5d0 prometheus stack\uc744 \uc801\uc6a9\ud55c \uc774\uc57c\uae30\ub97c \uc801\uc5b4\ubcf8\ub2e4. \\n- `trace` \uae30\ub2a5 \uad6c\ud604\uc744 search \ud558\ub358 \uc911 `open-telemetry` \ub97c \ubc1c\uacac\ud558\uc600\uc73c\uba70, \ub2e4\uc2dc \uad6c\ucd95\ud55c\ub2e4\uba74 `opentelemetry stack` \uc744 \ud65c\uc6a9\ud558\uc5ec scratch \ubd80\ud130 \uad6c\uc131\ud558\uaca0\uc9c0\ub9cc, `kube-prometheus-stack` \uc758 \ud3b8\ub9ac\ud568\uc744 \ud55c \ubc88 \ub9db\ubcf4\uace0 ~~\ub098\ub2c8 \ub3cc\uc544\uac00\uace0 \uc2f6\uc9c0 \uc54a\ub2e4.~~\\n\\n## 0. \uad6c\uc131\uc694\uc18c - \uc124\uce58\ud55c \ub0b4\uc6a9\\n----\\n* Prometheus - [ kube-prometheus-stack ] \\n* Loki - for log\\n* Tempo, Opentelemetry Agent - for trace\\n* Exporters - Redis, PostgreSQL\\n\\n### 0-1. Trace \uc124\uc815 \uad00\ub828 \\n- \uace0\ub824\ud55c \uc194\ub8e8\uc158\uc740 `Jaeger`, `Zipkin`, `Tempo` \ub4f1\uc774 \uc788\uc73c\uba70, \uc55e\uc758 2\uac1c \uc194\ub8e8\uc158\uc740 \uba87 \uac00\uc9c0 \ub2e8\uc810\uc774 \uc788\uc73c\uba70 \uc0ac\uc2e4 \uc0c1 deprecated \ub418\uc5b4 Tempo\ub97c \ud65c\uc6a9\ud558\uae30\ub85c \uacb0\uc815 \\n  - `Jeager` : CNCF \ub4f1\ub85d \ud504\ub85c\uc81d\ud2b8\uc774\ub098, \uc124\uc815\uc774 \ubcf5\uc7a1\ud568\\n  - `Zipkin` : Java \uc9c4\uc601\uc758 Trace\uc6a9 \uc194\ub8e8\uc158\uc73c\ub85c, \ucee4\ubba4\ub2c8\ud2f0 \ud65c\uc131\ud654\uac00 \ub418\uc5b4 \uc788\uc9c0 \uc54a\uc544 \uc774\uc288 \ud574\uacb0\uc758 \uc5b4\ub824\uc6c0. \\n  - `Tempo` : \uc0c1\ub300\uc801\uc73c\ub85c \uc2e0\uc0dd \ud504\ub85c\uc81d\ud2b8\uc774\ub098 `Grafana` \uc9c4\uc601\uc5d0\uc11c \uc8fc \ud504\ub85c\uc81d\ud2b8\ub85c \uad00\ub9ac\ud558\uace0, `Grafana` \uc0dd\ud0dc\uacc4\uc640 \uc5f0\ub3d9\ud558\uae30 \uc88b\uc74c. ~~UI! \uc9f1~~\\n- `Opentelemetry Auto-instruments`\ub97c \uc774\uc6a9\ud574 Trace data\ub97c \uc8fc\uc785\ud558\uace0\uc790 \ud558\uc600\uc73c\ub098, `8443 port`\ub97c k8s cluster node \ub2e8\uc5d0\uc11c \uc624\ud508\uc774 \ud544\uc694\ud558\uc5ec \uc774 \ubd80\ubd84\uc740 \uc0dd\ub7b5\ud568. ~~\uc0ac\uc2e4 namespace\ubcc4, service\ubcc4 operator \ubc30\ud3ec\uac00 \uadc0\ucc2e\uc740 \uac83\ub3c4..~~\\n\\n## 1. \ud658\uacbd \uc124\uc815\\n----\\n- \ud544\uc694 \ud504\ub85c\uadf8\ub7a8 \\n- k8s agent - connecto to cluster \\n- helm \\n\\n### 1-1. \ub2e4\uc6b4\ub85c\ub4dc \ud658\uacbd \\n#### 1-1-1. docker image download\\n\\n- private cluster \uc5d0\uc11c public docker image download\uac00 \ubd88\uac00\ub2a5 \ud558\ubbc0\ub85c, CI/CD Agent \uc11c\ubc84\uc5d0\uc11c \uc774\ubbf8\uc9c0 \ub2e4\uc6b4\ub85c\ub4dc \ud6c4 proxy \uc11c\ubc84(Azure Artifacts)\uc5d0 \ub4f1\ub85d\ud558\uc5ec k8s cluster\uc5d0 \uc124\uce58 \ud568\\n- \uc608\uc81c\\n\\n```bash\\n## sharedprdacr.azureacr.io \uc5d0 docker login \ub418\uc5b4 \uc788\uc5b4\uc57c \ud568.. azure service account \ub85c \uac00\ub2a5 \\n## 1. download\\ndocker pull docker.io/grafana/grafana:11.2.0 \\ndocker pull registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6\\n\\n## 2. taggging\\ndocker tag docker.io/grafana/grafana:11.2.0 sharedprdacr.azureacr.io/grafana/grafana:11.2.0\\ndocker tag registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6 sharedprdacr.azureacr.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6\\n\\n## 3. push \\ndocker push sharedprdacr.azureacr.io/grafana/grafana:11.2.0 \\ndocker push sharedprdacr.azureacr.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6\\n```\\n\\n## 2. install kube-prometheus-stack  \\n----\\n### 2-1. helm chart download \\n\\n- kube-prometheus-stack \uc124\uce58\\n- namespace \uba85 : `ns-prometheus`\\n\\n```bash\\nWORKDIR = /data/mgmt/prometheus\\n\\n### repo add\\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\\nhelm repo update\\n\\n### helm pull\\ncd ${WORKDIR}\\nhelm pull prometheus-community/kube-prometheus-stack \\n\\n```\\n\\n### 2-2. edit values.yaml \\n```yaml \\ncd kube-prometheus-stack/\\n\\n## values.yaml \ubc31\uc5c5\\ncp values.yaml values_241217.yaml \\n\\n### vi \ub85c values.yaml \ud30c\uc77c \ud3b8\uc9d1\\n## docker registry \ubcc0\uacbd\\nglobal.imageRegistry : \\"sharedacr.azureacr.io\\"\\nglobal.imagePullSecrets : [XXXXXXXX]\\n\\n## alert manager off \\nalertmanager.enabled : false\\n\\n## registry\\n:s/(docker.io|registry.k8s.io|quay.io|gcr.io|ghcr.io)/shared.azureacr.io/g\\n\\n\\n## grafana : k8s service \ub85c \ub4f1\ub85d \uc608\uc815\\n\\n```\\n### 2-3. install prometheus \\n```bash\\nkubectl config use-context <<cluster context>>; helm upgrade --install prometheus . -n ns-prometheus --create-namespace -f values.yaml\\n```\\n\\n## 3. Log \uc124\uc815\\n----\\n- loki\ub97c \ud1b5\ud558\uc5ec log\ub97c \uc804\ub2ec \ubc1b\uc544 cloud\uc5d0 Object storage \uc5d0 \uc800\uc7a5\ud558\ub294 \ub85c\uc9c1\uc744 \uad6c\ud604. \\n- Loki\uc5d0\uc11c\ub294 cloud storage \uc124\uc815, promtail \uc740 loki\uc640 \uc5f0\uacb0\ud558\ub294 \uc778\ud130\ud398\uc774\uc2a4 \uc124\uc815\uc774 \ud544\uc694 \\n- \uc124\uc815\uc744 \uc704\ud55c helm chart\ub294 grafana\ub97c \uc774\uc6a9\ud558\ubbc0\ub85c \uac1c\ubcc4 \uc124\uc815 \ubcc0\uacbd \uc804\uc5d0 \uba3c\uc800 \ub2e4\uc6b4 \ubc1b\uc544 \ub454\ub2e4. \\n\\n```bash\\n## helm repo add\\nhelm repo add grafana https://grafana.github.io/helm-charts\\nhelm repo update\\nhelm pull grafana-stack \\n```\\n\\n### 3-1. Loki \uc124\uc815\\n\\n#### 3-1-1. \uc6cc\ud0b9 \ub514\ub809\ud130\ub9ac \ubcc0\uacbd \\n```bash\\ncd ${WORKDIR}/grafana-stack/charts/loki-distributed\\n```\\n\\n#### 3-1-2. `values.yaml` \ud30c\uc77c \ud3b8\uc9d1\\n```yaml\\n...(\uc0dd\ub7b5)..\\nschemaConfig:\\n  configs:\\n  - from: \\"2024-09-11\\"\\n    index:\\n      period: 24h\\n      prefix: index_\\n    object_store: azure\\n    schema: v13\\n    store: tsdb\\nstorageConfig:\\n  azure:\\n    account_name: <\uc2a4\ud1a0\ub9ac\uc9c0\uc774\ub984> \\n    account_key: BO1dfASaldkjfklUXAlkjasldkfjalskjf==\\n    container_name: prometheus\\n    use_managed_identity: false\\n    request_timeout: 0 \\n  tsdb_shipper:\\n    active_index_directory: var/loki/index ### var \uc55e\uc5d0 / \ucd94\uac00\ud560 \uacbd\uc6b0 \uc5d0\ub7ec \ubc1c\uc0dd\\n    cache_location: var/loki/index_cache\\n    cache_ttl: 24h\\n  filesystem: \\n    directory: var/loki/chunks\\n...(\ud558\ub7b5)...\\n```\\n\\n#### 3-1-3. loki-distributed install\\n```bash\\n## k8s context \uc120\ud0dd\\nkubectl config use-context <cluster-context>\\n\\n## install \\nhelm upgrade --install loki . -n ns-prometheus -f values.yaml\\n```\\n\\n#### 3-1-4. Loki \uc124\uce58 \ud655\uc778 \\n\\n```bash\\n$ k get po -n ns-prometheus | grep -i loki \\nNAME                                                        READY   STATUS  RESTART AGE\\nloki-loki-distritubed-gateway-6dc5578cb9-j7scf              1/1     Running 0       10d\\nloki-loki-distritubed-distributor-6dc5578cb9-j7scf          1/1     Running 0       10d\\nloki-loki-distritubed-ingester-0                            1/1     Running 0       10d\\nloki-loki-distritubed-querier-0                             1/1     Running 0       10d\\nloki-loki-distritubed-query-frontend-8689676f4f-h8wn4-0     1/1     Running 0       10d\\n```\\n\\n### 3-2. promtail \uc124\uc815\\n\\n#### 3-2-1. \uc6cc\ud0b9 \ub514\ub809\ud130\ub9ac \ubcc0\uacbd \\n\\n```bash\\ncd $WORKDIR/grafana-stack/charts/promtail\\n```\\n\\n#### 3-2-2. `values.yaml` \ud30c\uc77c \ud3b8\uc9d1\\n```yaml \\n....(\uc0dd\ub7b5)....\\nclients:\\n- url: http://loki-loki-distributed-gateway/loki/api/v1/push\\n....(\ud558\ub7b5)....\\n```\\n\\n#### 3-2-3. `install promtail` \\n```bash \\nhelm upgradee --install promtail . -n ns-prometheus -f values.yaml\\n```\\n> [to-do] multi-line \ucc98\ub9ac\\n\\n\\n### 3-3. promtail \uc124\uce58 \ud655\uc778\\n```bash\\n$ k get po -n ns-prometheus | grep -i promtail\\nNAME                    READY   STATUS  RESTART AGE\\npromtail-2f8v9          1/1     Running 0       10d\\npromtail-2f8v9          1/1     Running 0       10d\\npromtail-2f8v9          1/1     Running 0       10d\\npromtail-2f8v9          1/1     Running 0       10d\\npromtail-2f8v9          1/1     Running 0       10d\\npromtail-2f8v9          1/1     Running 0       10d\\n``` \\n## 4. `Trace` \uc124\uc815\\n### 4-0. opentelemetry \uac1c\uc694 \\n### 4-1. \uc124\uce58 \uc21c\uc11c\\n- \uba3c\uc800 opentelemetry \uc124\uce58 \uc804\uc5d0 cert manager\ub97c \uc124\uce58\ud544\uc694(requirement)\\n- opentelemetry trace\ub294 CRD \ud615\ud0dc\ub85c \ubc30\ud3ec \ud6c4 operator resource\ub97c \uc124\uce58\ud558\uace0 collector \uc11c\ube44\uc2a4\ub97c \uae30\ub3d9\ud558\uc5ec \uc218\uc9d1\uc744 \uc704\ud55c \ud658\uacbd\uc744 \ub9cc\ub4e0\ub2e4. \\n- \uc55e\uc11c \uc0dd\uc131\ud55c collector\uc5d0 \uc2e4\uc81c trace \ub370\uc774\ud130\ub97c \uc804\uc1a1\ud558\ub294 agent\ub294 \uba87 \uac00\uc9c0 \ubc29\ubc95\uc73c\ub85c \uc124\uce58\ud560 \uc218 \uc788\ub294\ub370, CI/CD pipeline\uc744 \ud1b5\ud574 \uc790\ub3d9\ud654\ud558\ub824\uba74 \ud06c\uac8c 2\uac00\uc9c0 \ubc29\ubc95\uc73c\ub85c \uc815\ub9ac\ub41c\ub2e4. \\n    1. autoinstrument k8s object\ub97c \uc0dd\uc131\ud558\uc5ec label selector\ub97c \ud1b5\ud558\uc5ec \uc790\ub3d9 \uc801\uc6a9\\n    2. opentelemery agent\ub97c JVM \uad6c\ub3d9 \uc2dc library \ud615\ud0dc\ub85c \uc8fc\uc785\ud558\uace0, \uc124\uc815\uc5d0 \ud544\uc694\ud55c \ud658\uacbd\ubcc0\uc218\ub4e4\uc740 helm \ubc30\ud3ec \uc2dc \uc8fc\uc785\ub418\ub3c4\ub85d \uc870\uc791\\n- \uc55e\uc120 \ubc29\ubc95 \uc911 1\ubc88\uc758 \uacbd\uc6b0 cert manager\uc640 \ud1b5\uc2e0\uc744 \uc704\ud574\uc11c k8s cluster nodeport \uc5d0 \ub300\ud574 open\uc774 \ud544\uc694\ud558\ub098(`port : 8443`) private cluster\uc758 \ubc29\ud654\ubcbd open \ud544\uc694. ~~\uc815\ubcf4\ubcf4\uc548\ud300\uc5d0 \uc5f0\ub77d\ud558\uae30 \uadc0\ucc2e...~~. 2\ubc88 \ubc29\ubc95\uc73c\ub85c \uc9c4\ud589\\n- \uacb0\ub860\uc801\uc73c\ub85c \uc124\uce58 \uc21c\uc11c\\n    0. cert manager \uc124\uce58\\n    1. opentelemetry operator \\n    2. opentelemetry collector\\n    3. opentelemetry instrument\\n      - JVM \uc2e4\ud589 \uc2dc opentelemetry agent library\ub85c \uc2e4\ud589 \uc8fc\uc785 \\n\\n- helm repo add\\n```bash\\nhelm repo add open-telemetry https://github.com/open-telemetry/opentelemetry-helm-charts\\nhelm repo update\\nhelm pull \\n```\\n\\n\\n### 4-2. `cert manager` \uc124\uce58\\n- k8s \ub0b4\ubd80 TLS \ud1b5\uc2e0\uc5d0 \ub300\ud574 \uc778\uc99d \ucc98\ub9ac\ud558\ub294 \ubaa8\ub4c8\ub85c \\n- \ud1b5\uc0c1 self-signed TLS \uc778\uc99d\uc11c\ub85c \ud1b5\uc2e0 \uac00\ub2a5\ud558\ub3c4\ub85d \uc124\uc815\ud574 \uc90c \\n\\n```bash\\n# default \uc124\uce58\\nkubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.161/cert-manager.yaml \\n\\n# \uc124\uce58 \ud655\uc778\\n$ k get po -n \\nNAME                                        READY   STATUS  RESTART AGE\\ncert-manager-54f448d676d-cgznw              1/1     Running 0       10d\\ncert-manager-cainjector-7fc66c5787-gbpjk    1/1     Running 0       10d\\ncert-manager-webhook-fb4d6fb7-7zn7j         1/1     Running 0       10d\\n```\\n\\n### 4-3. `opentelemetry operator` \uc124\uce58\\n\\n```bash\\ncd ${WORKDIR}/opentelemetry-helm-charts/charts/opentelemetry-operator\\n```\\n#### 4-3-1. `values.yaml` \ud3b8\uc9d1\ub0b4\uc6a9\\n```yaml \\n## \ubcc0\uacbd \ub0b4\uc6a9 : image repostiroy \\n....(\uc911\ub7b5)....\\nmanager:\\n  image:\\n    repository: sharedprdacr.azureacr.io/open-telemetry/opentelemetry-operator/opentelemetry-operator\\n    tag: \\"\\"\\n  collectorImage:\\n    repository: sharedprdacr.azureacr.io/open-telemetry/opentelemetry-operator/opentelemetry-collector\\n    tag: 0.110.0\\n....(\uc0dd\ub7b5)....\\n\\nkubeRBACProxy:\\n  image:\\n    repository: sharedprdacr.azureacr.io/brancz/kube-rbac-proxy\\n\\n```\\n#### 4-3-2. `opentelemetry-collector` \uc124\uce58\\n\\n- values.yaml \ud3b8\uc9d1\\n\\n\\n```yaml\\n....(\uc0dd\ub7b5) - tempo \uc124\uc815....\\nmode: \\"deployment\\" # deployment\ub85c \ubcc0\uacbd\\nconfig:\\n  exporters:\\n    otlp:\\n      endpoint: \\"http://tempo.ns-prometheus.svc.cluster.local:4317\\"  ## tempo\ub97c \uc774\uc6a9\ud560 \uac83\uc73c\ub85c exporter\ub85c tempo\ub97c \uc9c0\uc815 , Tempo \uc124\uce58\ub294 \ub2e4\uc74c\uc808 \ucc38\uc870\\n      tls:\\n        insecure: true\\n# \ubcc0\uacbd \uc0ac\ud56d\uc740 \uc544\ub2c8\uc9c0\ub9cc, \uc911\uc694 \uc124\uc815 \\n  processors:\\n    batch: {} \\n    memory_limiter:\\n      check_interval: 5s\\n      limit_percentage: 80\\n      spike_limit_percentage: 25\\n  receivers:\\n    jaeger: # jaeger\\n      protocols: \\n        grpc: \\n          endpoint: ${env:MY_POD_PI}:14250\\n        thrift_http:\\n          endpoint: ${env:MY_POD_IP}:14268\\n        thrift_compact:\\n          endpoint: ${env:MY_POD_IP}:6831\\n    otlp: # otlp\\n      protocols:\\n        grpc:\\n          endpoint: ${env:MY_POD_IP}:4317\\n        http:\\n          endpoint: ${env:MY_POD_IP}:4318\\n    prometheus:\\n      config:\\n        scrape_configs:\\n        - job_name: opentelemetry_collector\\n          scrape_interval: 10s\\n          static_configs:\\n          - targets:\\n            - ${env:MY_POD_IP}:8888\\n    zipkin:\\n      endpoint: ${env:MY_POD_IP}:9411\\n  service:\\n    telemetry:\\n      metrics:\\n        address: ${env:MY_POD_IP}:8888\\n    extensions:\\n      - health_check\\n    pipelines:\\n      logs:\\n        exportors:\\n          - debug\\n        processors:\\n          - memory_limiter\\n          - batch\\n        receivers:\\n          - otlp\\n      metrics:\\n        exporters:\\n          - debug\\n        processors:\\n          - memory_limiter\\n          - batch\\n        receivers:\\n          - otlp\\n          - prometheus\\n      traces:\\n        exportoers:\\n          - debug\\n        processors:\\n          - memory_limiter\\n          - batch\\n        receivers:\\n          - otlp\\n          - jaeger\\n          - zipkin\\n```\\n \\n- `helm install` \\n\\n\\n```bash\\ncd ${WORKDIR}/opentelemetry-helm-charts/charts/opentelemetry-collector\\nhelm upgrade --install otel-collector . -f values.yaml\\n```\\n\\n### 4-4. `opentelemetry-instatruments` \uc124\uc815\\n- instruments \uc124\uc815 \ubc29\ubc99\uc5d0\ub294 \uc5ec\ub7ec \uac00\uc9c0\uac00 \uc788\uc73c\uba70, \uc55e\uc11c \uc0b4\ud3b4\ubcf8 \ubc14\uc640 \uac19\uc774 auto-instruments\ub97c \uc124\uc815\ud558\uc5ec resource \uc0dd\uc131 \uc2dc tag\ub97c \ud65c\uc6a9\ud558\uc5ec \uc790\ub3d9 \uc8fc\uc785\ub418\ub294 \ud658\uacbd\uc740 \uc544\ub2c8\ub2e4. \\n- \ud574\ub2f9 \uc124\uc815\uc744 \uc704\ud574\uc11c\ub294 **certManager Webhook** \uc124\uc815\uc774 \ud544\uc694\ud558\uba70 \uc774\ub294 **cluster \uc758 8443 port open \ud544\uc694**\\n- \uc5ec\uae30\uc11c\ub294 instrument\ub97c \ubcc4\ub3c4\ub85c \uc124\uce58\ud558\uc9c0 \uc54a\uace0, \ubcf4\ub0b4\ub294 \uc11c\ube44\uc2a4\uc5d0\uc11c lib \ud30c\uc77c\uc744 agent \ud615\ud0dc\ub85c \ucd94\uac00\ud558\uc5ec collector\uc5d0 \uc804\uc1a1\ud558\ub294 \ubc29\ubc95\uc744 \ud0dd\ud588\ub2e4. \\n- \ucc38\uace0 \uc0ac\ud56d\uc73c\ub85c auto-instruments \uc124\uc815\uc744 \uc704\ud55c manifests \ud30c\uc77c\uc740 \uc544\ub798\uc640 \uac19\ub2e4. \\n\\n#### 4-4-1. [\ucc38\uace0] otel-instrumentation \\n```yaml\\napiVersion: opentelemetry.io/v1alpha1\\nkind: Instrumentation\\nmetadata:\\n  name: otel-instrumentation \\nspec:\\n  exporter:\\n    endpoint: \\" http://otel-collector-opentelemetry-collector.ns-prometheus:4317\\"\\n  propagators:\\n    - tracecontext\\n    - baggage\\n  sampler:\\n    type: parentbased_traceidratio\\n    argument: \\"0.25\\"\\n  python:\\n    env:\\n    - name: OTEL_EXPORTER_OTLP_ENDPOINT\\n      value: http://otel-collector-opentelemetry-collector.ns-prometheus:4318\\n  dotnet:\\n    env:\\n    - name: OTEL_EXPORTER_OTLP_ENDPOINT\\n      value: http://otel-collector-opentelemetry-collector.ns-prometheus:4318\\n  go:\\n    env:\\n    - name: OTEL_EXPORTER_OTLP_ENDPOINT\\n      value: http://otel-collector-opentelemetry-collector.ns-prometheus:4318\\n```\\n\\n> [\ucc38\uace0] otel-instrumentation \uc124\uce58\ub97c \uc704\ud55c \uba85\ub839\uc5b4 \\n```bash\\nkubectl config use-context <<cluster-context>>;\\nhelm upgrade --install --set \\"manager.collectorImage.repository=sharedprdacr.azureacr.io/opentelemetry-collector-k8s\\" \\\\\\n                       --set \\"admissionWebhooks.certManager.enabled=false \\\\ \\n                       --set admissionWebhooks.autoGenerateCert.enabled=true\\n                       opentelemetry-operator . -f values.yaml -n ns-prometheus \\n```\\n\\n\\n> [\ucc38\uace0] otel operator \uc7ac\uc124\uce58\ud560 \uacbd\uc6b0 \uc0ad\uc81c\uac00 \ud544\uc694\ud55c CRD \ubaa9\ub85d\\n\\n| \ub300\uc0c1 | \uc0ad\uc81c \uba85\ub839 | \\n|--|--|\\n| instrumentations.opentelemetry.io | kubectl delete crd instrumentations.opentelemetry.io |\\n| opampbridges.opentelemetry.io | kubectl delete crd opampbridges.opentelemetry.ioopampbridges.opentelemetry.io |\\n| opentelemetrycollectors.opentelemetry.io | kubectl delete crd opentelemetrycollectors.opentelemetry.io | \\n\\n\\n## 5. `Tempo` \uc124\uce58\\n- Tempo\ub294 `trace` \ub97c \uc704\ud55c OSS library \uc911 \ud558\ub098\ub85c grafana community version\uc5d0\uc11c \ud655\uc778 \uac00\ub2a5 \\n\\n### 5-1. `values.yaml` \ud3b8\uc9d0 \\n```yaml\\n....(\uc0dd\ub7b5)....\\ntempo:\\n  metricsGenerator:\\n    enabled: true\\n    repoteWriteUrl: \\"http://prometheus-kube-promethus-prometheus.ns-prometheus:9090/api/v1/write\\"\\n  ........\\n  retention: 24h\\n  storage:\\n    trace:\\n      backend: azure\\n      azure:\\n        container_name: grafana-tempo\\n        storage_account_name: <<STORAGE_ACCOUNT_NAME>>\\n        storage_account_key: <<STORAGE_ACCOUNT_KEY>>\\n      local:\\n        path: /var/tempo/traces\\n      wal:\\n        path: /var/tempo/wal\\n  receivers:\\n    opencensus:\\n    otlp:\\n      protocols:\\n        grpc:\\n          endpoint: \\"0.0.0.0:4317\\"\\n        http:\\n          endpoint: \\"0.0.0.0:4318\\"\\n```\\n\\n### 5-2. `Tempo` install\\n```bash\\ncd ${WORKDIR}/grafana-stack/charts/tempo\\nkubectl config use-context <<cluster-context>>; helm upgrade --install tempo . -n ns-prometheus\\n```\\n\\n## 6. Exporter \uc124\uce58\\n### 6-1. `postgresql-exporter` \uc124\uce58\\n#### 6-1-1. \uc124\uc815 \uac12 \ubcc0\uacbd\\n```yaml\\nimage:\\n  registry: quay.io\\n  repository: prometheuscommunity/postgres-exporter\\n\\nservice:\\n  type: ClusterIP\\n  port: 80\\n  targetPort: 9187\\n  name: http\\n  labels: {}\\n  annotaions: \\n    prometheus.io/path: /metrics\\n    prometheus.io/scrape: \\"true\\"\\nserviceMonitor:\\n  enabled: true\\n  namespace: ns-prometheus\\n  interval: 30s\\n  telemetryPath: /metrics\\n  labels: pg-dev\\n  timeout: 10s\\nprometheusRule:\\n  enabled: false\\n```\\n\\n#### 6-1-2. `postgresql-exporter` \uc124\uce58\\n```bash\\ncd ${WORKDIR}/postgres_exporter/prometheus-postgre-exporter\\nhelm upgrade --install prometheus-postgres-exporter . -f postgre-exporter.yaml -n ns-prometheus \\n```\\n\\n#### 6-1-3. `prometheus exporter` \uc124\uc815\\n```yaml\\n# prometheus config \\n....\\nprometheusSpec:\\n  additionalScrapeConfigs:\\n  ## for pg\\n  - job_name: pg_exporter\\n    metrics_path: /metrics\\n    scrape_interval: 60s\\n    scrape_timeout: 30s\\n    static_configs:\\n    - targets:\\n      - prometheus-postgres-exporter:80\\n  ## for redis \\n  - job_name: redisexporter\\n    static_configs:\\n    - targets:\\n      - redis-exporter-prometheus-reids-exporter:9121\\n```\\n### 6-2. `redis-exporter` \uc124\uce58\\n- oliver006/redis_exporter \ud65c\uc6a9 : [github\uc8fc\uc18c](https://github.com/oliver006/redis_exporter)\\n\\n#### 6-2-1. `values.yaml` \ud3b8\uc9d1 \\n```yaml\\n# \ud655\uc778 \\nservice:\\n  type: ClusterIP\\n  port: 9121\\n  portName: redis-exporter\\n```\\n## 7. [\ucc38\uace0 \uc0ac\uc774\ud2b8]\\n\\n## 8. Epilog\\n- k8s \uc11c\ube44\uc2a4 \ub178\ucd9c\uc744 L7 LB\ub97c \ud1b5\ud558\uc5ec `domain`\uc744 \uc5f4\uc5b4\uc57c \ud558\ub294 \uad6c\uc870\uc778\ub370, \ud574\ub2f9 \uae30\ub2a5 \uc2b9\uc778\uc744 \uc815\ubcf4\ubcf4\uc548\ud300\uc5d0\uc11c \ub2f4\ub2f9\ud558\uc5ec, \ud558\ub098 `domain` \ud574\uc81c\ud558\uae30 \uae4c\ub2e4\ub86d\uace0 \uc808\ucc28\ub3c4 \uc624\ub798 \uac78\ub824, `manifest` \ud30c\uc77c\uc744 ~~\ud55c\ub540 \ud55c\ub540 \uc218\uc815\ud558\uc5ec~~ \uad6c\ucd95\ud558\uc600\uc73c\ub098 ~~\uc0bd\uc9c8 \uc778\ub4ef...~~\\n- `multi-cluster` \uc801\uc6a9\uacfc multicluster\ub97c \ud1b5\ud569\ud55c `Thanos` \uc801\uc6a9\uae30\ub3c4 \ucd94\uac00\ud560 \uc608\uc815\uc774\ub2e4. \\n\\n\\n---"},{"id":"/2024/11/01/fifth-Redis-cluster","metadata":{"permalink":"/2024/11/01/fifth-Redis-cluster","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2024-11-01-fifth-Redis-cluster.md","source":"@site/blog/2024-11-01-fifth-Redis-cluster.md","title":"Redis A-S(Active-Standby/Master-Slave) cluster \uad6c\ucd95\uae30","description":"summary","date":"2024-11-01T16:16:01.000Z","tags":[{"inline":true,"label":"Redis Cluster","permalink":"/tags/redis-cluster"},{"inline":true,"label":"kubernetes","permalink":"/tags/kubernetes"}],"readingTime":3.285,"hasTruncateMarker":true,"authors":[{"name":"Hanbyul Cho","title":"Engineer","url":"https://github.com/hansgun","page":{"permalink":"/authors/hansgun"},"socials":{"linkedin":"https://www.linkedin.com/in/hanbyulcho1/","github":"https://github.com/hansgun"},"imageURL":"https://github.com/hansgun.png","key":"hansgun"}],"frontMatter":{"layout":"single","title":"Redis A-S(Active-Standby/Master-Slave) cluster \uad6c\ucd95\uae30","date":"2024-11-01 16:16:01 -0600","categories":"work","tags":["Redis Cluster","kubernetes"],"author_profile":false,"toc":true,"toc_label":"On This Page","toc_icon":"cog","toc_position":"sticky","authors":["hansgun"]},"unlisted":false,"prevItem":{"title":"Setup Prometheus on private k8s cluster","permalink":"/2024/12/18/forth-prometheus"},"nextItem":{"title":"AKS terraform\uc73c\ub85c \uc2dc\uc791\ud574\ubcf4\uae30","permalink":"/2024/10/26/sixth-terrform-aks"}},"content":"> summary\\n\x3c!-- truncate --\x3e\\n\\n# Prolog \\n- \uacfc\uc81c\ub85c \uc791\uc131\ud55c \ub0b4\uc6a9\uc784 \\n- OSS DB \ud639\uc740 cache \uc194\ub8e8\uc158\uc740 \uc131\ub2a5, \ud6a8\uc728\uc131\uc744 \uac15\uc870\ud558\ub294 \ub300\uc2e0, \uc815\ud569\uc131\uc744 \ud3ec\ud568\ud55c \uc548\uc815\uc131\uc5d0 \ub300\ud574\uc11c\ub294 \uc0c1\uc6a9 \uc81c\ud488\ub4e4\uc5d0 \ube44\ud574 \uae30\ubcf8 \uae30\ub2a5\uc5d0\uc11c \uc81c\uacf5\ud558\uc9c0 \uc54a\ub294 \uacbd\uc6b0\uac00 \ub9ce\ub2e4. \\n- \uace0\uac00\uc6a9\uc131 \uc124\uc815 Oracle RAC \ub4f1\uc758 session failover \ub4f1\uc758 detail \ud55c \uc124\uc815\uc744 \uad6c\ud604\ud558\uae30\ub294 \uc27d\uc9c0 \uc54a\ub2e4. \\n- OSS \ub808\ubca8\uc5d0\uc11c\ub294 Primary\uc5d0 \ubb38\uc81c\uac00 \uc0dd\uacbc\uc744 \uacbd\uc6b0 Primary failover\uc5d0 \uc911\uc810\uc744 \ub454 replication \uae30\ubc18\uc740 PSS \ud639\uc740 PSA \uad6c\uc870\uc758 \uace0\uac00\uc6a9\uc131 \uad6c\ud604\uc774 \uc9c0\ubc30\uc801\uc778 \uac83 \uac19\ub2e4. \\n- \uc774\ub7ec\ud55c \uad6c\uc870\ub294 primary \uc6b4\uc601\uc5d0 \uc774\uc288\uac00 \uc0dd\uacbc\uc744 \uacbd\uc6b0 vote \ud558\ub294 \uc808\ucc28\uc5d0\uc11c \uc758\ubbf8 \uc788\ub294 \uacb0\uacfc\ub97c \ub3c4\ucd9c\ud558\uae30 \uc704\ud558\uc5ec `quorum` \uae30\ubc18\uc758 \uc54c\uace0\ub9ac\uc998 \uc774 \uc601\ud5a5\uc744 \ubbf8\uce5c \uac83 \uac19\ub2e4.   \\n\\n# 1. Task \uac1c\uc694\\n----\\n- key-value store \uc774\uc790 cache\ub85c \ub9ce\uc774 \ud65c\uc6a9\ub418\ub294 Redis \ub294 \uba54\ubaa8\ub9ac \uae30\ubc18\uc758 \ud718\ubc1c\uc131 \uc800\uc7a5 \uc194\ub8e8\uc158\uc774\ub2e4. \\n- persistency\ub97c \uc704\ud558\uc5ec RDBMS\uc640 \uac19\uc774 \uc800\uc7a5\uc7a5\uce58\uc5d0 \ub370\uc774\ud130 \ub3d9\uae30\ud654\ub97c \uc8fc\uae30\uc801\uc73c\ub85c \uc218\ud589\ud560 \uc218 \uc788\uc73c\ub098 \uc774 \uacbd\uc6b0 \uba54\ubaa8\ub9ac \uc0c1\uc758 \ub370\uc774\ud130 \ubcc0\uacbd\uc774 \uc81c\ud55c\ub41c\ub2e4. \uc131\ub2a5 \uc800\ud558 \uc774\uc288\ub3c4 \ubc1c\uc0dd\ud55c\ub2e4. \\n  - \ucd5c\uadfc\uc5d0\ub294 ahead logging \ubc29\uc2dd\uc73c\ub85c sequential \ud558\uac8c log\ub97c \uae30\ub85d\ud558\uc5ec \uc624\ubc84\ud5e4\ub4dc\ub97c \uc904\uc774\uace0, \uc774\ub97c streaming \ud615\ud0dc\ub85c Standby \uc11c\ubc84\uc5d0 \uc804\uc1a1\ud558\uc5ec \uc900\uc2e4\uc2dc\uac04 \ub3d9\uae30\ud654\ub97c \ud1b5\ud55c \uace0\uac00\uc6a9\uc131\uc744 \uad6c\ud604\ud560 \uc218 \uc788\ub2e4. \\n- sharding \uacfc \uac19\uc740 \uac1c\ub150\uc73c\ub85c key \uac12\uc744 \ubd84\uc0b0 \ucc98\ub9ac \ud558\uc5ec \ubd80\ud558 \ubd84\uc0b0\ud560 \uc218 \uc788\ub3c4\ub85d cluster \uad6c\uc131\uc774 \uac00\ub2a5\ud558\ub2e4. \\n- \uc774\uc5d0 \ub300\ud55c \uad6c\ud604\uc744 \uc544\ub798\uc640 \uac19\uc774 \uc9c4\ud589\ud558\uc600\ub2e4. \\n- \uad00\ub9ac\ud615 k8s cluster \uc5d0\uc11c pod \ud615\ud0dc\ub85c redis cluster \uad6c\uc131\uacfc \ubaa8\ub2c8\ud130\ub9c1\uc744 \uad6c\uc131\ud558\uc600\ub2e4. \\n\\n1. GKE \uad6c\uc131\\n2. Redis Cluster \uad6c\uc131 \\n  - `StatefulSet` \ud65c\uc6a9 \\n  - Primary-Secondary \uad6c\uc870 \uad6c\uc131 \\n3. Prometheus \uc124\uce58 \\n  - redis-exporter \uc124\uc815 \\n4. redis \uc811\uadfc application \uc0dd\uc131 \ubc0f HA \uc811\uadfc \uc124\uc815, key \ubd84\uc0b0 \uc800\uc7a5 \uc5ec\ubd80 \ud655\uc778 \\n\\n## 1-1. \uad6c\uc131\ub3c4 \\n![redis cluster \uad6c\uc131\ub3c4](./cluster_archi.png)\\n\\n# 2. GKE \uad6c\uc131\\n- GKE \uad6c\uc131\uc740 `SDK` \uc124\uce58 \uc774\ud6c4 `CLI` \ub97c \ud1b5\ud574 install \uc9c4\ud589 \\n\\n```bash\\n## env \\nexport CLUSTER_NAME=\\"gke-han-cluster\\"\\nexport ZONE=\\"asia-east1\\"\\nexport NUM_NODES=2\\nexport MACHINE_TYPE=\\"e2-medium\\"\\n\\ngcloud auth login q*****@gmail.com\\n\\ngcloud auth list\\n\\ngcloud projects list\\n# PROJECT_ID: ninth-age-4*****-p0\\n# NAME: My First Project\\n# PROJECT_NUMBER: 39*******\\n\\nexport PROJECT_ID=\\"your-project-id\\"\\ngcloud config set project $PROJECT_ID\\n\\ngcloud services enable container.googleapis.com\\n\\ngcloud container clusters create $CLUSTER_NAME \\\\ \\n    --zone $ZONE \\\\\\n    --num-nodes $NUM_NODES \\\\\\n    --machine-type $MACHINE_TYPE \\\\\\n    --enable-ip-alias \\\\\\n    --network \\"default\\" --disk-size=50GB \\\\\\n    --subnetwork \\"default\\"\\n    --enable-workload-identity\\n\\ngcloud components install kubectl\\n\\ngcloud container clusters get-credentials $CLUSTER_NAME --zone $ZONE\\n\\n# add disk \\ngcloud compute disks create --size=10GB --zone=asia-east1-a nfs-disk\\n```\\n\\n# 3. k8s \uc6cc\ud06c\ub85c\ub4dc \uad6c\uc131\\n## 3-1. \ud30c\uc77c \uad6c\uc870\\n```bash\\n$ tree v1 -L 1\\n\u251c\u2500\u2500 00.disk.yaml\\n\u251c\u2500\u2500 01.sts.yaml\\n\u251c\u2500\u2500 02.svc.yaml\\n\u251c\u2500\u2500 04.grafana_svc.yaml\\n\u2514\u2500\u2500 backup\\n```\\n# (\uc791\uc131\uc911)\\n# 7. [\ucc38\uace0 \uc0ac\uc774\ud2b8]\\n\\n# Epilog\\n- \\n\\n---"},{"id":"/2024/10/26/sixth-terrform-aks","metadata":{"permalink":"/2024/10/26/sixth-terrform-aks","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2024-10-26-sixth-terrform-aks.md","source":"@site/blog/2024-10-26-sixth-terrform-aks.md","title":"AKS terraform\uc73c\ub85c \uc2dc\uc791\ud574\ubcf4\uae30","description":"summary","date":"2024-10-26T16:16:01.000Z","tags":[{"inline":true,"label":"Redis Cluster","permalink":"/tags/redis-cluster"},{"inline":true,"label":"kubernetes","permalink":"/tags/kubernetes"}],"readingTime":6.105,"hasTruncateMarker":true,"authors":[{"name":"Hanbyul Cho","title":"Engineer","url":"https://github.com/hansgun","page":{"permalink":"/authors/hansgun"},"socials":{"linkedin":"https://www.linkedin.com/in/hanbyulcho1/","github":"https://github.com/hansgun"},"imageURL":"https://github.com/hansgun.png","key":"hansgun"}],"frontMatter":{"layout":"single","title":"AKS terraform\uc73c\ub85c \uc2dc\uc791\ud574\ubcf4\uae30","date":"2024-10-26 16:16:01 -0600","categories":"work","tags":["Redis Cluster","kubernetes"],"author_profile":false,"toc":true,"toc_label":"On This Page","toc_icon":"cog","toc_position":"sticky","authors":["hansgun"]},"unlisted":false,"prevItem":{"title":"Redis A-S(Active-Standby/Master-Slave) cluster \uad6c\ucd95\uae30","permalink":"/2024/11/01/fifth-Redis-cluster"},"nextItem":{"title":"Authorizer Architecuture","permalink":"/2020/01/29/second-blog"}},"content":"> summary\\n\x3c!-- truncate --\x3e\\n\\n# Prolog \\n- Prometheus\ub97c k8s cluster\uc5d0 \uc124\uce58\ud558\ub294 \uc2e4\uc2b5\uc744 \uc9c4\ud589\ud558\uace0\uc790 \uc124\uce58 \ud658\uacbd\uc744 \uc54c\uc544\ubcf4\ub358 \uc911, Azure\uc758 \ubb34\ub8cc credit\uc774 \uc788\uc5b4 AKS\ub97c \uc124\uce58\ud574 \ubcf4\uc558\ub2e4. \\n- \ud3c9\uc18c \uc2e4\uc2b5\ud574\ubcf4\uace0\uc790 \ud588\ub358 `Terraform` \uc744 \uc774\uc6a9\ud558\uc5ec Provisioning \ud558\ub294 history\ub97c \uae30\ub85d\uc5d0 \ub0a8\uae30\uace0\uc790 \uc791\uc131\ud55c blog \uc774\ub2e4. \\n- \uc2e4\uc81c \uc791\uc5c5 \ud6c4 2\uac1c\uc6d4 \uc774\ud6c4\uc5d0 \uc791\uc131\ud558\ub294 \ub0b4\uc6a9\uc774\ub77c \uae30\uc5b5\uc774 \uac00\ubb3c\uac00\ubb3c \ud558\ub2e4... \\n\\n# 1. \uac1c \uc694\\n----\\n* Prometheus - [ kube-prometheus-stack ] \\n* Loki - for log\\n* Tempo, Opentelemetry Agent - for trace\\n* Exporters - Redis, PostgreSQL\\n\\n## 1-1. \ud30c\uc77c \uad6c\uc870 \\n```bash\\n$ tree\\n.\\n\u251c\u2500\u2500 az_terra.sh\\n\u2514\u2500\u2500 terraform\\n    \u251c\u2500\u2500 0_variables.tf\\n    \u251c\u2500\u2500 1_providers.tf\\n    \u251c\u2500\u2500 2_ssh.tf\\n    \u251c\u2500\u2500 3_main.tf\\n    \u251c\u2500\u2500 7_output.tf\\n    \u251c\u2500\u2500 main.tfplan\\n    \u251c\u2500\u2500 terraform.tfstate\\n    \u2514\u2500\u2500 terraform.tfstate.backup\\n```\\n\\n## 1-2. \uc804\uccb4 \ud750\ub984 - `az_terra.sh` \\n```bash\\nexport USERNAME=********@hotmail.com\\naz account list --query \\"[?user.name==\'********@hotmail.com\'].{Name:name, ID:id, Default:isDefault}\\" --output Table\\n\\naz group  list --query \\"[?location==\'koreacentral\']\\"\\n\\n[\\n  {\\n    \\"cloudName\\": \\"AzureCloud\\",\\n    \\"homeTenantId\\": \\"b42795af-74d2-****-*****-****\\",\\n    \\"id\\": \\"9e7c5e29-60c3-4a20-8afd-*********\\",\\n    \\"isDefault\\": true,\\n    \\"managedByTenants\\": [],\\n    \\"name\\": \\"Microsoft Azure \uc2a4\ud3f0\uc11c\uc27d 2\\",\\n    \\"state\\": \\"Enabled\\",\\n    \\"tenantId\\": \\"b42795af-74d2-****-*****-****\\",\\n    \\"user\\": {\\n      \\"name\\": \\"********@hotmail.com\\",\\n      \\"type\\": \\"user\\"\\n    }\\n  }\\n]\\n\\n## \\nexport MSYS_NO_PATHCONV=1\\n\\naz account set --subscription \\"9e7c5e29-60c3-******-****-********\\"\\n\\naz ad sp create-for-rbac --name vmss_rbac --role Contributor --scopes /subscriptions/9e7c5e29-60c3-******-****-********\\n\\n{\\n  \\"appId\\": \\"a887e74b-****-4ae5-84d6-********\\",\\n  \\"displayName\\": \\"vmss_rbac\\",\\n  \\"password\\": \\"q5b8Q~D&&&&&&*****jec_k\\",\\n  \\"tenant\\": \\"b42795af-74d2-****-*****-****\\"\\n}\\n\\n\\nexport ARM_SUBSCRIPTION_ID=\\"9e7c5e29-60c3-******-****-********\\"\\nexport ARM_TENANT_ID=\\"b42795af-74d2-****-*****-****\\"\\nexport ARM_CLIENT_ID=\\"a887e74b-****-4ae5-84d6-********\\"\\nexport ARM_CLIENT_SECRET=\\"q5b8Q~D&&&&&&*****jec_k\\"\\n\\n\\naz ad sp create-for-rbac --name <service_principal_name> --role Contributor --scopes /subscriptions/<subscription_id>\\n\\n\\nprovider \\"azurerm\\" {\\n  features {}\\n\\n  subscription_id   = \\"9e7c5e29-60c3-******-****-********\\"\\n  tenant_id         = \\"b42795af-74d2-****-*****-****\\"\\n  client_id         = \\"a887e74b-****-4ae5-84d6-********\\"\\n  client_secret     = \\"q5b8Q~D&&&&&&*****jec_k\\"\\n}\\n\\nclient_certificate = <sensitive>\\nclient_key = <sensitive>\\ncluster_ca_certificate = <sensitive>\\ncluster_password = <sensitive>\\ncluster_username = <sensitive>\\nhost = <sensitive>\\nkey_data = \\"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCuQxKT5JhDZD+************/r11DJCx/SlwguHFucV3R+wQSF7/3WwZaqANUS/ArN+zUoAjqmST/UfaJ5JBg4aehoHmzzzhVn/cqA3V31V2rJog5siIYYFFan19VgxsqS3/QH9kxU0/QjQ3PqLOe0hPrbENpnJ8t1BgszokaTPToaJrCMIoCzgY7mBWVnseqgG6qU8vowMM**************tmFKD/tCylxBTecfAsbJBiJt5lcx8eF5dIS**************I7IhAyeHKicexZbt82Lxu6tXwJERYBQ5lkX4Kp************iMuJQ9QEChPCKveKlmU+Tlg3n1P0fNbCo+oWCdRuP6hm4HrU/+Z**********rCCU= generated-by-azure\\"\\nkube_config = <sensitive>\\nkubernetes_cluster_name = \\"cluster-diverse-bear\\"\\nresource_group_name = \\"rg-premium-koala\\"\\n```\\n\\n## 1-3. Terraform \uc124\uc815 \uac12 \\n- `terraform-docs`\ub85c \uc0dd\uc131\ud568 \\n\\n```bash\\n$ brew install terraform-docs\\n...\\n$ terraform-docs markdown table \\\\\\n    --output-file README.md \\\\\\n    --output-mode inject \\\\\\n    .\\n\\nREADME.md updated successfully\\n```\\n\\n### 1-3-1. README.md file \ub0b4\uc6a9 - `terraform-docs` \uc0dd\uc131\ud30c\uc77c\\n---\\n> \x3c!-- BEGIN_TF_DOCS --\x3e\\n> ### Requirements\\n> \\n> | Name | Version |\\n> |------|---------|\\n> | <a name=\\"requirement_terraform\\"></a> [terraform](#requirement\\\\_terraform) | >=1.0 |\\n> | <a name=\\"requirement_azapi\\"></a> [azapi](#requirement\\\\_azapi) | ~>1.5 |\\n> | <a name=\\"requirement_azurerm\\"></a> [azurerm](#requirement\\\\_azurerm) | ~>3.0 |\\n> | <a name=\\"requirement_random\\"></a> [random](#requirement\\\\_random) | ~>3.0 |\\n> | <a name=\\"requirement_time\\"></a> [time](#requirement\\\\_time) | 0.9.1 |\\n> \\n> ### Providers\\n> \\n> | Name | Version |\\n> |------|---------|\\n> | <a name=\\"provider_azapi\\"></a> [azapi](#provider\\\\_azapi) | 1.12.1 |\\n> | <a name=\\"provider_azurerm\\"></a> [azurerm](#provider\\\\_azurerm) | 3.93.0 |\\n> | <a name=\\"provider_random\\"></a> [random](#provider\\\\_random) | 3.6.0 |\\n> \\n> ### Modules\\n> \\n> No modules.\\n> \\n> ### Resources\\n> \\n> | Name | Type |\\n> |------|------|\\n> | [azapi_resource.ssh_public_key](https://registry.terraform.io/providers/azure/azapi/latest/docs/resources/> resource) | resource |\\n> | [azapi_resource_action.ssh_public_key_gen](https://registry.terraform.io/providers/azure/azapi/latest/docs/> resources/resource_action) | resource |\\n> | [azurerm_kubernetes_cluster.k8s](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/> resources/kubernetes_cluster) | resource |\\n> | [azurerm_resource_group.rg](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/> resources/resource_group) | resource |\\n> | [random_pet.azurerm_kubernetes_cluster_dns_prefix](https://registry.terraform.io/providers/hashicorp/> random/latest/docs/resources/pet) | resource |\\n> | [random_pet.azurerm_kubernetes_cluster_name](https://registry.terraform.io/providers/hashicorp/random/> latest/docs/resources/pet) | resource |\\n> | [random_pet.rg_name](https://registry.terraform.io/providers/hashicorp/random/latest/docs/resources/pet) | > resource |\\n> | [random_pet.ssh_key_name](https://registry.terraform.io/providers/hashicorp/random/latest/docs/resources/> pet) | resource |\\n> \\n> ### Inputs\\n> \\n> | Name | Description | Type | Default | Required |\\n> |------|-------------|------|---------|:--------:|\\n> | <a name=\\"input_msi_id\\"></a> [msi\\\\_id](#input\\\\_msi\\\\_id) | The Managed Service Identity ID. Set this value > if you\'re running this example using Managed Identity as the authentication method. | `string` | `null` | > no |\\n> | <a name=\\"input_node_count\\"></a> [node\\\\_count](#input\\\\_node\\\\_count) | The initial quantity of nodes for the > node pool. | `number` | `2` | no |\\n> | <a name=\\"input_resource_group_location\\"></a> [resource\\\\_group\\\\_location]> (#input\\\\_resource\\\\_group\\\\_location) | Location of the resource group. | `string` | `\\"koreacentral\\"` | no |\\n> | <a name=\\"input_resource_group_name_prefix\\"></a> [resource\\\\_group\\\\_name\\\\_prefix]> (#input\\\\_resource\\\\_group\\\\_name\\\\_prefix) | Prefix of the resource group name that\'s combined with a random ID > so name is unique in your Azure subscription. | `string` | `\\"rg\\"` | no |\\n> | <a name=\\"input_username\\"></a> [username](#input\\\\_username) | The admin username for the new cluster. | > `string` | `\\"azureadmin\\"` | no |\\n> \\n> ### Outputs\\n> \\n> | Name | Description |\\n> |------|-------------|\\n> | <a name=\\"output_client_certificate\\"></a> [client\\\\_certificate](#output\\\\_client\\\\_certificate) | n/a |\\n> | <a name=\\"output_client_key\\"></a> [client\\\\_key](#output\\\\_client\\\\_key) | n/a |\\n> | <a name=\\"output_cluster_ca_certificate\\"></a> [cluster\\\\_ca\\\\_certificate]> (#output\\\\_cluster\\\\_ca\\\\_certificate) | n/a |\\n> | <a name=\\"output_cluster_password\\"></a> [cluster\\\\_password](#output\\\\_cluster\\\\_password) | n/a |\\n> | <a name=\\"output_cluster_username\\"></a> [cluster\\\\_username](#output\\\\_cluster\\\\_username) | n/a |\\n> | <a name=\\"output_host\\"></a> [host](#output\\\\_host) | n/a |\\n> | <a name=\\"output_key_data\\"></a> [key\\\\_data](#output\\\\_key\\\\_data) | n/a |\\n> | <a name=\\"output_kube_config\\"></a> [kube\\\\_config](#output\\\\_kube\\\\_config) | n/a |\\n> | <a name=\\"output_kubernetes_cluster_name\\"></a> [kubernetes\\\\_cluster\\\\_name]> (#output\\\\_kubernetes\\\\_cluster\\\\_name) | n/a |\\n> | <a name=\\"output_resource_group_name\\"></a> [resource\\\\_group\\\\_name](#output\\\\_resource\\\\_group\\\\_name) | n/a |\\n>\\n> \x3c!-- END_TF_DOCS --\x3e\\n---\\n\\n### 1-3-2. `0-variables.tf` \ud30c\uc77c \ub0b4\uc6a9 \uc911 \ubcc0\uacbd \uc0ac\ud56d\\n```hcl\\nvariable \\"resource_group_location\\" {\\n  type        = string\\n  default     = \\"koreacentral\\"  ###### region \uc124\uc815 ######\\n  description = \\"Location of the resource group.\\"\\n}\\n\\n\\nvariable \\"node_count\\" {\\n  type        = number\\n  description = \\"The initial quantity of nodes for the node pool.\\"\\n  default     = 2  ###### cluster node \uac2f\uc218 \uc124\uc815 : minimal \uc124\uc815 ######\\n}\\n\\n\\nvariable \\"username\\" {\\n  type        = string\\n  description = \\"The admin username for the new cluster.\\"\\n  default     = \\"azureadmin\\" ###### username for cluster (default value \uadf8\ub300\ub85c \uc774\uc6a9) ######\\n}\\n```\\n\\n### 1-3-3. `1_providers.tf` \\n```hcl\\nterraform {\\n  required_version = \\">=1.0\\"\\n\\n  required_providers {\\n    azapi = {\\n      source  = \\"azure/azapi\\"\\n      version = \\"~>1.5\\"\\n    }\\n    azurerm = {\\n      source  = \\"hashicorp/azurerm\\"\\n      version = \\"~>3.0\\"\\n    }\\n    random = {\u3139\\n      source  = \\"hashicorp/random\\"\\n      version = \\"~>3.0\\"\\n    }\\n    time = {\\n      source  = \\"hashicorp/time\\"\\n      version = \\"0.9.1\\"\\n    }\\n  }\\n}\\n\\nprovider \\"azurerm\\" {\\n  features {}\\n\\n  subscription_id   = \\"9e7c5e29-60c3-******-****-********\\"  ###### \uc124\uc815\uc5d0 \ub9de\uac8c \ubcc0\uacbd\ud568 ######\\n  tenant_id         = \\"b42795af-74d2-****-*****-****\\"       ###### \uc124\uc815\uc5d0 \ub9de\uac8c \ubcc0\uacbd\ud568 ######\\n  client_id         = \\"a887e74b-****-4ae5-84d6-********\\"    ###### \uc124\uc815\uc5d0 \ub9de\uac8c \ubcc0\uacbd\ud568 ######\\n  client_secret     = \\"q5b8Q~D&&&&&&*****jec_k\\"             ###### \uc124\uc815\uc5d0 \ub9de\uac8c \ubcc0\uacbd\ud568 ######\\n}\\n\\n```\\n\\n### 1-3-4. `2_ssh.tf` : \ubcc0\uacbd\uc0ac\ud56d \uc5c6\uc74c\\n\\n### 1-3-5. `3_main.tf` \\n\\n```hcl\\n....(\uc0dd\ub7b5)....\\n\\n  default_node_pool {\\n    name       = \\"agentpool\\"          ###### pool \uc774\ub984 \uc124\uc815 ######\\n    vm_size    = \\"Standard_D2_v2\\"     ###### vm size \uc124\uc815 ######\\n    node_count = var.node_count\\n  }\\n....(\uc0dd\ub7b5)....\\n```\\n\\n### 1-3-6. `7_output.tf` : \ubcc0\uacbd \uc5c6\uc74c\\n\\n## 2. Terraform \uc2e4\uc0dd \\n\\n```mermaid\\ngraph LR;\\n  A[terraform init] -.-> B[terraform plan] -.-> C[terraform apply] -.-> D[terraform destroy];\\n  A -.-> E[terraform validate] -.-> B;\\n  C -.-> F[terraform output] -.-> G[terraform show];\\n  G -.-> D;\\n```\\n\\n```bash\\n$ terraform init \\n$ terraform plan \\n$ terraform apply \\n```\\n\\n## 7. [\ucc38\uace0 \uc0ac\uc774\ud2b8]\\n- ~~\uae30\uc5b5\uc774 \uc548\ub0a8~~\\n\\n## 8. Epilog\\n- idempotent IaC \uc744 \ud1b5\ud574\uc11c infra provisioning \uad00\ub9ac\ub97c \ud574\ubcf4\uace0\uc790 \ud588\ub294\ub370, \uc2e4\uc81c \uc5c5\ubb34 \ud658\uacbd\uc5d0\uc11c\ub294 \ubcf4\uc548\uc801 \ubb38\uc81c\uc640 \ubc18\ubcf5 \uc5c5\ubb34\uc758 \ubd80\uc7ac \ub4f1\uc73c\ub85c \ub3c4\uc785 \ub418\uc9c0 \uc54a\uc558\ub2e4. side-project\ub85c \ubc16\uc5d0 \uacbd\ud5d8\ud560 \uc218 \uc5c6\uc744 \uac83 \uac19\ub2e4. \\n- \uc608\uc804 Hadoop \uc124\uce58\uc758 \ubcf5\uc7a1\ud568\uc744 \ud574\uacb0\ud558\uace0\uc790 ansible\ub85c IaC \uad6c\uc131\ud55c \uc801\uc774 \uc788\ub294\ub370, \uc790\ub8cc\ub97c \ub0a8\uae30\uc9c0 \uc54a\uc558\uc5c8\uace0, \uc774\uc804 \ud68c\uc0ac\uc758 \uacbd\ud5d8\uc774\ub77c \uc790\ub8cc\uac00 \uc5c6\uc5b4 \uae30\ub85d\uc73c\ub85c \ub0a8\uae30\uc9c0 \ubabb\ud574 \uc544\uc27d\ub2e4.  \\n\\n\\n---"},{"id":"/2020/01/29/second-blog","metadata":{"permalink":"/2020/01/29/second-blog","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-01-29-second-blog.md","source":"@site/blog/2020-01-29-second-blog.md","title":"Authorizer Architecuture","description":"summary","date":"2020-01-28T06:38:01.000Z","tags":[{"inline":true,"label":"docker-compose","permalink":"/tags/docker-compose"},{"inline":true,"label":"authorizer","permalink":"/tags/authorizer"}],"readingTime":7.495,"hasTruncateMarker":true,"authors":[{"name":"Hanbyul Cho","title":"Engineer","url":"https://github.com/hansgun","page":{"permalink":"/authors/hansgun"},"socials":{"linkedin":"https://www.linkedin.com/in/hanbyulcho1/","github":"https://github.com/hansgun"},"imageURL":"https://github.com/hansgun.png","key":"hansgun"}],"frontMatter":{"layout":"post","title":"Authorizer Architecuture","date":"2020-01-28 06:38:01 -0600","author_profile":false,"categories":"work","tags":["docker-compose","authorizer"],"permlink":"/categories/","toc":true,"toc_label":"On This Page","toc_icon":"cog","authors":["hansgun"]},"unlisted":false,"prevItem":{"title":"AKS terraform\uc73c\ub85c \uc2dc\uc791\ud574\ubcf4\uae30","permalink":"/2024/10/26/sixth-terrform-aks"},"nextItem":{"title":"Setup CI/CD [Jenkins+Nexus for Spring, Docker, R]","permalink":"/2019/11/17/first-blog"}},"content":"> summary\\n\x3c!-- truncate --\x3e\\n\\n> _project \uad6c\ud604 \uae30\ubc18. single server\uc5d0 single proxy, 2-java Oauth container\ub97c \uc5f0\uacb0\ud55c \ud615\ud0dc\uc784_\\n\\n# 1. \uae30\ubcf8 \uac1c\ub150\\n\\n- \uc678\ubd80 \ud1b5\uc2e0\uc740 \ub2e8\uc77c interface\ub97c \ud1b5\ud558\uc5ec \uc218\ud589. (nginX reverse proxy \uc774\uc6a9, port 8078[\ud604\uc7ac\ubc84\uc804])\\n- \uc2e4\uc81c authorizer component\ub294 \uc774\uc911\ud654 \uad6c\uc131\ud558\uba70, \uc678\ubd80\uc5d0 \ub178\ucd9c\ub418\ub294 port\ub294 \uc5c6\uc74c\\n- \uc704 2\uac00\uc9c0 component\ub294 health check fail \uc2dc \uc790\ub3d9\uc73c\ub85c \uc7ac\uae30\ub3d9. (\ud604\uc7ac\ub294 proxy\ub9cc \uc124\uc815\ub41c \uc0c1\ud0dc ==> restart:always)\\n- cache layer\ub294 redis \ub97c \ud65c\uc6a9\ud55c\ub2e4.\\n\\n# 2. \uad6c\ucd95 \ubc29\uc548\\n\\n- \uac1c\ubcc4 component\ub294 docker container\ub97c \uc774\uc6a9.\\n- \ud558\ub098\uc758 \uc11c\ube44\uc2a4\ud654\ub97c \uc704\ud558\uc5ec docker-compose\ub85c \uad6c\uc131\\n- \ud604 \ubc84\uc804\uc740 \ud558\ub098\uc758 \ubb3c\ub9ac \uc11c\ubc84\uc5d0\uc11c docker container\ub97c \uc5ec\ub7ec \uac1c \ub744\uc6b0\ub294 \uad6c\uc131\uc774\uba70, \ubb3c\ub9ac \uc11c\ubc84\uc758 cluster\ud654 \ud560 \uacbd\uc6b0 \ucd94\uac00 solution \ud544\uc694\\n\\n## 2-1. implementation\\n\\n- $HOME directory \uad00\ub828 \ud30c\uc77c \uad6c\uc870\\n\\n```\\n\u251c\u2500\u2500 Dockerfile ## authorizer \uc0dd\uc131 Dockerfile\\n\u251c\u2500\u2500 Dockerfile_proxy ## proxy(nginx) \uc0dd\uc131 Dockerfile\\n\u251c\u2500\u2500 docker-compose.yml ## docker-compose file\\n\u251c\u2500\u2500 make_docker_compose.sh ## \uc804\uccb4 \ud504\ub85c\uc138\uc2a4\ub97c \uc218\ud589\ud558\uae30 \uc704\ud55c shell script\\n\u251c\u2500\u2500 nginx.conf ## Dockerfile_proxy \uc5d0\uc11c \uc0ac\uc6a9\ud560 nginx config \ud30c\uc77c\\n\u251c\u2500\u2500 .env ## docker-compose \ud658\uacbd \ubcc0\uc218\\n\u2514\u2500\u2500 target ## authorizer jar \ud30c\uc77c\uc774 \uc0dd\uc131\ub418\ub294 \uc704\uce58\\n```\\n\\n- \uc124\uce58 \ubc29\ubc95\\n\\n```\\nsh make_docker_compose.sh <\uc124\uce58\ub41c \ubb3c\ub9ac\uc11c\ubc84 IP address> ## IP address\ub294 .env\uc5d0\uc11c redis\uc5d0\uc11c \ud65c\uc6a9\\n```\\n\\n## 2-2. \uac01 \ud30c\uc77c\uc758 \ub0b4\uc6a9\\n\\n### 2-2-1. shell script\\n\\n`make_docker_compose.sh`\\n\\n```bash\\n#!/bin/bash\\n\\n## check parameter length\\nif [ \\"$#\\" -gt 3 ]; then\\n        echo \\"$# is Illegal number of parameters.\\"\\n        echo \\"Usage: $0 [authoizer1_host_ip] [authorizer2_host_ip]\\"\\n        exit 1\\nfi\\nargs=(\\"$@\\")\\n\\n## print parameter list\\nfor (( c=0; c<$#; c++   ))\\n  do\\n    echo \\"$c th parameter = ${args[$c]}\\";\\n  done\\n\\n## set-up .env file\\necho \\"APP_HOST_NAME=auth_app\\" > .env\\nif [ \\"$#\\" -eq 2 ]; then\\n        echo \\"APP_HOST_IP1=${args[0]}\\" >> .env\\n        echo \\"APP_HOST_IP2=${args[1]}\\" >> .env\\nelif [ \\"$#\\" -eq 1 ]; then\\n        echo \\"APP_HOST_IP1=${args[0]}\\" >> .env\\n        echo \\"APP_HOST_IP2=${args[0]}\\" >> .env\\nelse\\n        echo \\"APP_HOST_IP1=127.0.0.1\\" >> .env\\n        echo \\"APP_HOST_IP2=127.0.0.1\\" >> .env\\nfi\\n\\n## build jar file for authorizer\\nmvn -e -DskipTests=true clean install\\n\\n## docker-compose up\\ndocker-compose up --build -d\\n\\n```\\n\\n### 2-2-2. docker-compose \uad00\ub828 \ud30c\uc77c\\n\\n- docker-compose.yml : service \uc804\uccb4 \ub0b4\uc6a9 \ubc0f dependency \uc2e4\ud589 \uc21c\uc11c \ub4f1 container \uc81c\uc5b4\\n- .env : docker-compose.yml \uc5d0\uc11c \uc0ac\uc6a9\ud560 \ud658\uacbd \ubcc0\uc218 \uc815\uc758\\n- Dockerfile : authorizer(springboot OAuth2 server) container image\\n- Dockerfile_proxy : nginx \uc124\uce58 \uc774\ubbf8\uc9c0\ub85c \ub2e4\uc74c \uc808(2-2-3\uc5d0\uc11c \uc124\uba85)\\n\\n`docker-compose.yml`\\n\\n- \uc21c\uc11c\ub300\ub85c redis, authorizer1, authorizer2, proxy 4\uac1c\uc758 \uc774\ubbf8\uc9c0\ub97c \uc0dd\uc131\\n- proxy service \uad6c\uc131 \uc911 links \ubd80\ubd84\uc740 \uba85\uba85\ub41c service\ub97c ip\uac00 \uc544\ub2cc name\uc73c\ub85c \uc811\uadfc \uac00\ub2a5\ud558\ub3c4\ub85d \uc124\uc815\ud568\\n\\n\\n```yaml\\n# VERSION 1.0.0\\n# AUTHOR: project\\n# DESCRIPTION: project Authorizer\\n# BUILD: docker-compose -p <name> -d up -build\\n# SOURCE: https://github.com/\\n\\nversion: \'2.1\'\\n\\nservices:\\n#  redis:\\n#    image: redis:3.2.12\\n#    ports:\\n#      - \\"6379:6379\\"\\n\\n  authorizer1:\\n    #hostname: authorizer1\\n    #container_name: authorizer1\\n    build:\\n      context: .\\n    environment:\\n      - REDIS_HOST=redis\\n      - TZ=Asia/Seoul\\n    extra_hosts:\\n      - ${APP_HOST_NAME}:${APP_HOST_IP1} ## .env \uc5d0 \uc815\uc758\ub41c \ubcc0\uc218 \uc0ac\uc6a9\\n    #ports: ## port expose test.. authorizer container \uc678\ubd80\ub85c open \ub418\ub294 port \uc5c6\uc74c\\n    #  - \\"8085:8081\\"\\n#    depends_on:\\n#      - redis\\n\\n  authorizer2:\\n    build:\\n      context: .\\n    environment:\\n      - REDIS_HOST=redis\\n      - TZ=Asia/Seoul\\n    extra_hosts:\\n      - ${APP_HOST_NAME}:${APP_HOST_IP2}\\n    #ports:\\n    #  - \\"8086:8081\\"\\n#    depends_on:\\n#      - redis\\n\\n  proxy:\\n    restart: always\\n    build:\\n      context: .\\n      dockerfile: Dockerfile_proxy\\n#    ports:\\n#      - \\"8084:80\\" ## nginX 80 port\ub97c \uc678\ubd80 8084 port\ub85c expose\\n    depends_on:\\n      - authorizer1\\n      - authorizer2\\n    links: ## docker \ub0b4\ubd80 \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c \uc811\uadfc\ud558\uae30 \uc704\ud558\uc5ec hostname \uc815\uc758\\n      - authorizer1:authorizer1\\n      - authorizer2:authorizer2\\n    #extra_hosts:\\n    #  - \\"authorizer1:${APP_HOST_IP1}\\"\\n    #  - \\"authorizer2:${APP_HOST_IP2}\\"\\n    healthcheck:\\n      test: \\"curl --fail http://localhost:8084/ || exit 1\\"\\n      interval: 1m\\n      timeout: 1s\\n      retries: 5\\n```\\n\\n### 2-2-3. NginX \uad00\ub828\\n\\n- Dockerfile_proxy : nginx image\ub97c \uc0dd\uc131\ud558\ub294 dockerfile\\n- nginx.conf : nginx \uc5d0\uc11c \uc0ac\uc6a9\ud560 config \ub97c \ubbf8\ub9ac \uc815\uc758\ud55c \ub0b4\uc6a9\\n\\n`Dockerfile_proxy`\\n\\n```\\n# VERSION v.1.0.0\\n# AUTHOR: hansgun\\n# DESCRIPTION: project authorizer proxy\\n# BUILD: docker build --rm -t project/proxy .\\n# SOURCE: https://github.com/\\n\\nFROM nginx:latest\\n\\nCOPY ./nginx.conf /etc/nginx/ ## current directory \uc5d0\uc11c conf \ud30c\uc77c \ubcf5\uc0ac\\n```\\n\\n`nginx.conf`\\n\\n- \\\\*\\\\* \ud2b9\uc774\uc810\uc740 nginx \uc5d0\uc11c authorizer1,2 docker \uc811\uadfc \uc2dc IP\uac00 \uc544\ub2cc hostname\uc73c\ub85c \uc811\uadfc\ud558\uc5ec, container \ub0b4\ubd80\uc758 port\ub97c \uc9c1\uc811 \uc811\uadfc \ud568\\n\\n```\\n# /etc/nginx/nginx.conf\\n\\nuser  nginx;\\nworker_processes  1;\\n\\nerror_log  /var/log/nginx/error.log warn;\\npid        /var/run/nginx.pid;\\n\\n\\nevents {\\n    worker_connections  1024;\\n}\\n\\nhttp {\\n    include mime.types;\\n\\n    upstream myapp1 {\\n        least_conn;\\n        server authorizer1:8081 max_fails=1 fail_timeout=2s; # authorizer1,2 \uc5d0 \ub300\ud55c load balancing \uc124\uc815\\n        server authorizer2:8081 max_fails=1 fail_timeout=2s; # docker\ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c hostname\uc73c\ub85c \uc811\uadfc. IP, port \ubd88\ud544\uc694\\n    }\\n\\n    server {\\n        listen 8078;\\n        access_log /var/log/nginx/tomcat_access.log;\\n        location /spring-security-oauth-server { ## authorizer application.yml \uc758 spring.servlet.context-path\\n            proxy_pass http://myapp1;\\n                proxy_set_header X-Real-IP $remote_addr;\\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\\n                proxy_set_header X-NginX-Proxy true;\\n                proxy_set_header Host $host:$server_port;\\n                proxy_redirect off;\\n        }\\n    }\\n}\\n```\\n\\n\\n## 3. \uc2e4\ud589\uacb0\uacfc\\n\\n`sh make_docker_compose.sh 192.168.1.168 <-- IP\ub294 \ud658\uacbd\uc5d0 \ub9de\uac8c \ubcc0\uacbd \ud544\uc694`\\n\\n\\n```\\n0 th parameter = 192.168.1.168\\n[INFO] Error stacktraces are turned on.\\n[INFO] Scanning for projects...\\n[INFO]\\n[INFO] -------------< kr.co.project.feedernet:projectAuthorizer >--------------\\n[INFO] Building projectAuthorizer 1.0.0-SNAPSHOT\\n[INFO] --------------------------------[ jar ]---------------------------------\\n... \uc911\uac04 \uc0dd\ub7b5 ...\\n[INFO] ------------------------------------------------------------------------\\n[INFO] BUILD SUCCESS\\n[INFO] ------------------------------------------------------------------------\\n[INFO] Total time:  5.199 s\\n[INFO] Finished at: 2020-01-03T09:43:27+09:00\\n[INFO] ------------------------------------------------------------------------\\nBuilding authorizer1\\nStep 1/12 : FROM java:8-jre\\n ---\x3e e44d62cf8862\\nStep 2/12 : ENV APP_HOME /usr/lib/authorizer\\n ---\x3e Using cache\\n ---\x3e 4da19107a7c2\\nStep 3/12 : RUN echo \\"Asia/Seoul\\" > /etc/timezone\\n ---\x3e Using cache\\n ---\x3e d6d7ac7e2220\\nStep 4/12 : RUN dpkg-reconfigure -f noninteractive tzdata\\n ---\x3e Using cache\\n ---\x3e 3b9bc1f0b6aa\\nStep 5/12 : RUN useradd -ms /bin/bash -d ${APP_HOME} authorizer\\n ---\x3e Using cache\\n ---\x3e 2bad24c3166b\\nStep 6/12 : ARG JAR_FILE=\\"target/*.jar\\"\\n ---\x3e Using cache\\n ---\x3e 5f886986b5a2\\nStep 7/12 : COPY ${JAR_FILE} ${APP_HOME}/authorizer.jar\\n ---\x3e 76556a94980a\\nStep 8/12 : RUN chown authorizer: -R ${APP_HOME}\\n ---\x3e Running in 6f4cc39bc255\\nRemoving intermediate container 6f4cc39bc255\\n ---\x3e a16310494008\\nStep 9/12 : EXPOSE 8081\\n ---\x3e Running in 74d861e17a9f\\nRemoving intermediate container 74d861e17a9f\\n ---\x3e f0a15efc2613\\nStep 10/12 : USER authorizer\\n ---\x3e Running in f9b2f072847a\\nRemoving intermediate container f9b2f072847a\\n ---\x3e 13821a47ae94\\nStep 11/12 : WORKDIR ${APP_HOME}\\n ---\x3e Running in 6a1cc49da232\\nRemoving intermediate container 6a1cc49da232\\n ---\x3e 8f3abf8226fe\\nStep 12/12 : ENTRYPOINT [\\"java\\",\\"-Djava.security.egd=file:/dev/./urandom\\",\\"-Xms256m\\",\\"-Xmx512m\\",\\"-server\\",\\"-XX:+UseNUMA\\",\\"-XX:+UseParallelGC\\",\\"-XX:+AggressiveOpts\\",\\"-XX:+UseFastAccessorMethods\\",\\"-jar\\",\\"authorizer.jar\\"]\\n ---\x3e Running in ce9aa6573758\\nRemoving intermediate container ce9aa6573758\\n ---\x3e 759031b1bfd8\\nSuccessfully built 759031b1bfd8\\nSuccessfully tagged projectauthorizer_authorizer1:latest\\nBuilding authorizer2\\nStep 1/12 : FROM java:8-jre\\n ---\x3e e44d62cf8862\\nStep 2/12 : ENV APP_HOME /usr/lib/authorizer\\n ---\x3e Using cache\\n ---\x3e 4da19107a7c2\\nStep 3/12 : RUN echo \\"Asia/Seoul\\" > /etc/timezone\\n ---\x3e Using cache\\n ---\x3e d6d7ac7e2220\\nStep 4/12 : RUN dpkg-reconfigure -f noninteractive tzdata\\n ---\x3e Using cache\\n ---\x3e 3b9bc1f0b6aa\\nStep 5/12 : RUN useradd -ms /bin/bash -d ${APP_HOME} authorizer\\n ---\x3e Using cache\\n ---\x3e 2bad24c3166b\\nStep 6/12 : ARG JAR_FILE=\\"target/*.jar\\"\\n ---\x3e Using cache\\n ---\x3e 5f886986b5a2\\nStep 7/12 : COPY ${JAR_FILE} ${APP_HOME}/authorizer.jar\\n ---\x3e Using cache\\n ---\x3e 76556a94980a\\nStep 8/12 : RUN chown authorizer: -R ${APP_HOME}\\n ---\x3e Using cache\\n ---\x3e a16310494008\\nStep 9/12 : EXPOSE 8081\\n ---\x3e Using cache\\n ---\x3e f0a15efc2613\\nStep 10/12 : USER authorizer\\n ---\x3e Using cache\\n ---\x3e 13821a47ae94\\nStep 11/12 : WORKDIR ${APP_HOME}\\n ---\x3e Using cache\\n ---\x3e 8f3abf8226fe\\nStep 12/12 : ENTRYPOINT [\\"java\\",\\"-Djava.security.egd=file:/dev/./urandom\\",\\"-Xms256m\\",\\"-Xmx512m\\",\\"-server\\",\\"-XX:+UseNUMA\\",\\"-XX:+UseParallelGC\\",\\"-XX:+AggressiveOpts\\",\\"-XX:+UseFastAccessorMethods\\",\\"-jar\\",\\"authorizer.jar\\"]\\n ---\x3e Using cache\\n ---\x3e 759031b1bfd8\\nSuccessfully built 759031b1bfd8\\nSuccessfully tagged projectauthorizer_authorizer2:latest\\nBuilding proxy\\nStep 1/2 : FROM nginx:latest\\n ---\x3e f949e7d76d63\\nStep 2/2 : COPY ./nginx.conf /etc/nginx/\\n ---\x3e Using cache\\n ---\x3e de0942485c9f\\nSuccessfully built de0942485c9f\\nSuccessfully tagged projectauthorizer_proxy:latest\\nRecreating projectauthorizer_redis_1 ... done\\nRecreating projectauthorizer_authorizer2_1 ... done\\nRecreating projectauthorizer_authorizer1_1 ... done\\nRecreating projectauthorizer_proxy_1       ... done\\n```\\n\\n`docker-compose ps`\\n\\n```\\n             Name                            Command                       State                   Ports\\n-----------------------------------------------------------------------------------------------------------------\\nprojectauthorizer_authorizer1_1   java -Djava.security.egd=f ...   Up                      8081/tcp\\nprojectauthorizer_authorizer2_1   java -Djava.security.egd=f ...   Up                      8081/tcp\\nprojectauthorizer_proxy_1         nginx -g daemon off;             Up (health: starting)   0.0.0.0:8084->8078/tcp\\nprojectauthorizer_redis_1         docker-entrypoint.sh redis ...   Up                      0.0.0.0:6379->6379/tcp\\n\\n```\\n\\n`docker network inspect projectauthorizer_default`\\n\\n```js\\n[\\n    {\\n        \\"Name\\": \\"projectauthorizer_default\\",\\n        \\"Id\\": \\"ab7956cbd8e787be575c050acd842854ed18906bf89c9566b929b818a90fe006\\",\\n        \\"Created\\": \\"2020-01-02T08:28:09.400768103Z\\",\\n        \\"Scope\\": \\"local\\",\\n        \\"Driver\\": \\"bridge\\",\\n        \\"EnableIPv6\\": false,\\n        \\"IPAM\\": {\\n            \\"Driver\\": \\"default\\",\\n            \\"Options\\": null,\\n            \\"Config\\": [\\n                {\\n                    \\"Subnet\\": \\"172.29.0.0/16\\",\\n                    \\"Gateway\\": \\"172.29.0.1\\"\\n                }\\n            ]\\n        },\\n        \\"Internal\\": false,\\n        \\"Attachable\\": true,\\n        \\"Ingress\\": false,\\n        \\"ConfigFrom\\": {\\n            \\"Network\\": \\"\\"\\n        },\\n        \\"ConfigOnly\\": false,\\n        \\"Containers\\": {\\n            \\"13dba477f3abd8b6d346b956a2787561a7affc29eca268234d463231db0e4d16\\": {\\n                \\"Name\\": \\"projectauthorizer_proxy_1\\",\\n                \\"EndpointID\\": \\"16cd689ed587cb92b19813337a3944cccf7d5685c080ddbc6c25f1a7fbe93b91\\",\\n                \\"MacAddress\\": \\"02:42:ac:1d:00:05\\",\\n                \\"IPv4Address\\": \\"172.29.0.5/16\\",\\n                \\"IPv6Address\\": \\"\\"\\n            },\\n            \\"591a74c933dd05b9dccb29b2b56dd58dc5d42e1f1e6a0c3fdb54e7b384f103b2\\": {\\n                \\"Name\\": \\"projectauthorizer_authorizer1_1\\",\\n                \\"EndpointID\\": \\"13633a2221edf6874fecb11b1a7dea0c0ddbdf5ac80cacb27c59ffd06225784c\\",\\n                \\"MacAddress\\": \\"02:42:ac:1d:00:03\\",\\n                \\"IPv4Address\\": \\"172.29.0.3/16\\",\\n                \\"IPv6Address\\": \\"\\"\\n            },\\n            \\"6702531cb6602b36086c570dd12f830ba76a7279426d7a523056b77b902d17b4\\": {\\n                \\"Name\\": \\"projectauthorizer_redis_1\\",\\n                \\"EndpointID\\": \\"2fcaa3885607fdee1f46ea95f97ec534f71d38945fc347663a78c599bfdd7146\\",\\n                \\"MacAddress\\": \\"02:42:ac:1d:00:02\\",\\n                \\"IPv4Address\\": \\"172.29.0.2/16\\",\\n                \\"IPv6Address\\": \\"\\"\\n            },\\n            \\"a42280ac856a5778395a34dab634e3e511ff1fd45b98cd68e0946640193d3bd6\\": {\\n                \\"Name\\": \\"projectauthorizer_authorizer2_1\\",\\n                \\"EndpointID\\": \\"a9c34a66279c465706351d252745055037d5f0c819670e9a7fd10de3b0709179\\",\\n                \\"MacAddress\\": \\"02:42:ac:1d:00:04\\",\\n                \\"IPv4Address\\": \\"172.29.0.4/16\\",\\n                \\"IPv6Address\\": \\"\\"\\n            }\\n        },\\n        \\"Options\\": {},\\n        \\"Labels\\": {\\n            \\"com.docker.compose.network\\": \\"default\\",\\n            \\"com.docker.compose.project\\": \\"projectauthorizer\\",\\n            \\"com.docker.compose.version\\": \\"1.24.1\\"\\n        }\\n    }\\n]\\n```\\n\\n## 4. \uc811\uadfc \ud14c\uc2a4\ud2b8\\n\\n`http://<\uc11c\ubc84 IP>:8078/spring-security-oauth-server/`"},{"id":"/2019/11/17/first-blog","metadata":{"permalink":"/2019/11/17/first-blog","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-11-17-first-blog.md","source":"@site/blog/2019-11-17-first-blog.md","title":"Setup CI/CD [Jenkins+Nexus for Spring, Docker, R]","description":"summary","date":"2019-11-17T16:16:01.000Z","tags":[{"inline":true,"label":"jenkins","permalink":"/tags/jenkins"},{"inline":true,"label":"nexus OSS","permalink":"/tags/nexus-oss"},{"inline":true,"label":"CI/CD","permalink":"/tags/ci-cd"}],"readingTime":5.965,"hasTruncateMarker":true,"authors":[{"name":"Hanbyul Cho","title":"Engineer","url":"https://github.com/hansgun","page":{"permalink":"/authors/hansgun"},"socials":{"linkedin":"https://www.linkedin.com/in/hanbyulcho1/","github":"https://github.com/hansgun"},"imageURL":"https://github.com/hansgun.png","key":"hansgun"}],"frontMatter":{"layout":"post","title":"Setup CI/CD [Jenkins+Nexus for Spring, Docker, R]","date":"2019-11-17T16:16:01.000Z","categories":"work","tags":["jenkins","nexus OSS","CI/CD"],"author_profile":false,"toc":true,"toc_label":"On This Page","toc_icon":"cog","toc_position":"sticky","authors":["hansgun"]},"unlisted":false,"prevItem":{"title":"Authorizer Architecuture","permalink":"/2020/01/29/second-blog"},"nextItem":{"title":"Set up project dev environments","permalink":"/2020/01/30/third-blog"}},"content":"> summary\\n\x3c!-- truncate --\x3e\\n\\n## 0. \uad6c\uc131\uc694\uc18c\\n\\n- jenkins\\n- nexus OSS\\n- ansible\\n- docker\\n\\n## 1. Jenkins \uc124\uce58\\n\\n### 1-1. \ub2e4\uc6b4\ub85c\ub4dc \ubc0f \uc2e4\ud589\\n\\n```bash\\nwget http://mirrors.jenkins.io/war-stable/latest/jenkins.war\\n#java -jar jenkins.war --httpPort=8080 --prefix=/jenkins\\n```\\n\\n### 1-2. \uc811\uc18d\\n\\n```\\nhttp://<hostname>:8080/jenkins\\n```\\n\\n### 1-3. slave \uc124\uc815\\n\\n> `UI \uc5d0\uc11c Jenkins \uad00\ub9ac > \ub178\ub4dc\uad00\ub9ac \ub85c \uc62e\uae34\ud6c4 \uc2e0\uaddc\ub178\ub4dc \ub97c \uc5f4\uc5b4\ubd05\ub2c8\ub2e4:`  \\n> `1. \ub178\ub4dc\uba85\uc744 \uc785\ub825: \uc608\ub97c\ub4e4\uc5b4 slave-01`  \\n> `2. Permanent Agent \ub97c \uc120\ud0dd`  \\n> `\uc124\uc815 Page \uc5d0\uc11c:`  \\n> `1. Remote root directory \uc5d0 \uc785\ub825, \uc608\ub97c\ub4e4\uc5b4, /opt/jenkins.`  \\n> `2. Launch method \ub294 Launch Slave Agents via SSH \ub97c \uc120\ud0dd, host \uba85 \uc785\ub825\ud6c4 credential \ucd94\uac00`  \\n> `2.1 Credential \ucd94\uac00\uc2dc Slave node user, jenkins \uc640 \uadf8 password \ub97c \ub4f1\ub85d\ud568`  \\n> `2.2 \ud639\uc740 SSH Username with private key \uc120\ud0dd, From the jenkins master ~/.ssh  \uc120\ud0dd`  \\n> `2.2.1 master \uc5d0\uc11c`\\n\\n```bash\\nsudo su - jenkins;\\n\\n# generate key.\\nssh-keygen -t rsa;\\n\\n# copy master public key to slave.\\nssh-copy-id -i ~/.ssh/id_rsa.pub <hostname>; # \ud639\uc740 cat ~/.ssh/id_pub.rsa > authorized_keys\\n\\n# add config to ~/.ssh\\nvi ~/.ssh/config;\\nStrictHostKeyChecking no\\n\\n# chmod.\\nchmod 600 ~/.ssh/config\\n\\n# check connection to slave.\\nssh emb-a01;\\n```\\n\\n## 2. nexus \uc124\uce58\\n\\n```bash\\n# download.\\n# https://www.sonatype.com/download-oss-sonatype\\n\\n# change data directory.\\n# https://help.sonatype.com/repomanager3/installation/configuring-the-runtime-environment#ConfiguringtheRuntimeEnvironment-ConfiguringtheDataDirectory\\ncd <nexus-home>/bin;\\n\\nvi nexus.vmoptions;\\n-Xms2703m\\n-Xmx2703m\\n-XX:MaxDirectMemorySize=2703m\\n-XX:+UnlockDiagnosticVMOptions\\n-XX:+UnsyncloadClass\\n-XX:+LogVMOutput\\n-XX:LogFile=../sonatype-work/nexus3/log/jvm.log ## \ubcc0\uacbd\\n-XX:-OmitStackTraceInFastThrow\\n-Djava.net.preferIPv4Stack=true\\n-Dkaraf.home=.\\n-Dkaraf.base=.\\n-Dkaraf.etc=etc/karaf\\n-Djava.util.logging.config.file=etc/karaf/java.util.logging.properties\\n-Dkaraf.data=../sonatype-work/nexus3 ## \ubcc0\uacbd\\n-Djava.io.tmpdir=../sonatype-work/nexus3/tmp ## \ubcc0\uacbd\\n-Dkaraf.startLocalConsole=false\\n```\\n\\n## 3. nexus docker registry \uc124\uc815\\n\\n> Reference: [config reference](https://www.ivankrizsan.se/2016/06/09/create-a-private-docker-registry/)\\n\\n## 4. nexus \uc124\uc815\uc6a9 pom file\\n\\n### 4-1. pom.xml\\n\\n```xml\\n    <repositories>\\n        <repository>\\n            <id>central</id>\\n            <url>http://localhost:8081/repository/maven-public/</url>\\n            <snapshots>\\n                <enabled>true</enabled>\\n                <updatePolicy>always</updatePolicy>\\n            </snapshots>\\n        </repository>\\n    </repositories>\\n    <pluginRepositories>\\n        <pluginRepository>\\n            <id>central</id>\\n            <url>http://localhost:8081/repository/maven-public/</url>\\n            <releases>\\n                <enabled>true</enabled>\\n            </releases>\\n            <snapshots>\\n                <enabled>true</enabled>\\n            </snapshots>\\n        </pluginRepository>\\n    </pluginRepositories>\\n    <distributionManagement>\\n        <snapshotRepository>\\n            <id>snap</id>\\n            <url>http://localhost:8081/repository/maven-snapshots/</url>\\n        </snapshotRepository>\\n        <repository>\\n            <id>rel</id>\\n            <url>http://localhost:8081/repository/maven-releases/</url>\\n        </repository>\\n    </distributionManagement>\\n```\\n\\n### 4-2. mvn setting..\\n\\n```shell\\n# mvn -version \uc73c\ub85c maven_home \ud655\uc778 \ud6c4\\ncd $MAVEN_HOME.conf\\nvi settings.xml\\n```\\n\\n```xml\\n<servers>\\n    <server>\\n        <id>central</id>\\n        <username>$(nexus_username)</username>\\n        <password>$(nexus_passwd)</password>\\n    </server>\\n    <server>\\n        <id>snap</id>\\n        <username>$(nexus_username)</username>\\n        <password>$(nexus_passwd)</password>\\n    </server>\\n\\t<server>\\n        <id>rel</id>\\n        <username>$(nexus_username)</username>\\n        <password>$(nexus_passwd)</password>\\n    </server>\\n</servers>\\n```\\n\\n### 4-3. Deploy test\\n\\n```console\\nmvn -e -DskipTests=true clean install deploy;\\n```\\n\\n## 5. \ubc30\ud3ec \ub300\uc0c1 \uc11c\ubc84 \uc124\uc815\\n\\n### 5-1. docker private registry \ub4f1\ub85d\\n\\n```ksh\\n# /etc/docker/daemon.json \ud30c\uc77c \ud3b8\uc9d1\ud558\uc5ec secure \uc608\uc678 \ucc98\ub9ac \ub4f1\ub85d\\n{\\n    \\"insecure-registries\\": [\\"<ip>:<port>\\",\\"<domain>:<port>\\"]\\n}\\n\\n# \uc800\uc7a5\ud6c4 docker restart\\n# wheel group user\\nsudo systemctl stop docker\\nsudo systemctl start docker\\n\\n# <userID> \uacc4\uc815(group id : docker) \uc5d0\uc11c \uc815\ubcf4 \ud655\uc778\\n# docker info\uc758 \ub9c8\uc9c0\ub9c9 \uc139\uc158 \ud655\uc778\\ndocker info\\n------------------------------------\\n....(\uc0dd\ub7b5)....\\n Insecure Registries:\\n  <ip or domain>:<port>\\n   127.0.0.0/8\\n Live Restore Enabled: false\\n------------------------------------\\n```\\n\\n### 5-2. private registry login\\n\\n```sh\\n# private docker registry login\\n# docker login -u<userid> -p<password> <ip or domain>:<port>\\ndocker login -uadmin -p <ip or domain>:<port>\\npassword:\\n```\\n\\n### 5-3. image pull & \ud655\uc778\\n\\n```sh\\n# docker image pull\\ndocker pull <ip or domain>:<port>/app:1.0.0-SNAPSHOT\\n\\n# image \ud655\uc778\\ndocker images | grep -i jenkins\\n------------------------------------\\n<ip or domain>:<port>/app   1.0.0-SNAPSHOT      ec62cef80ecf        2 hours ago         235MB\\n------------------------------------\\n```\\n\\n## 6. Nexus R-plugin \uc124\uc815\\n\\n### 6-1. plugin \ub2e4\uc6b4\ub85c\ub4dc\\n\\n#### requirements\\n\\n- Apache Maven 3.3.3+\\n- OpenJDK 8\\n- Network access to https://repository.sonatype.org/content/groups/sonatype-public-grid\\n- nexus version\uacfc \ud638\ud658\ub418\ub294 plugin \uc744 \ub2e4\uc6b4 \ubc1b\ub294\ub2e4\\n\\n#### nexus,R plugin version\\n\\n<table>\\n<thead>\\n<tr>\\n<th>Plugin Version</th>\\n<th>Nexus Repository Version</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>v1.0.0</td>\\n<td>&lt;3.8.0-02</td>\\n</tr>\\n<tr>\\n<td>v1.0.1</td>\\n<td>&gt;=3.8.0-02</td>\\n</tr>\\n<tr>\\n<td>v1.0.2</td>\\n<td>&gt;=3.14.0-04</td>\\n</tr>\\n<tr>\\n<td>v1.0.3</td>\\n<td>&gt;=3.15.2-01</td>\\n</tr>\\n<tr>\\n<td>v1.0.4</td>\\n<td>&gt;=3.18.0-01</td>\\n</tr>\\n</tbody>\\n</table>\\n\\nplugin [Download link](https://github.com/sonatype-nexus-community/nexus-repository-r/releases)\\n\\n- nexus-repository-r-1.0.4.jar \uae30\uc900\uc73c\ub85c \uc544\ub798\uc5d0 \uc124\uba85\\n\\n### 6-2. R-plugin \uc124\uce58\\n\\n1.) \uc544\ub798\uc758 3\uac1c\uc758 \ud30c\uc77c \ubcf5\uc0ac\uc640 \uc124\uc815 \ucd94\uac00 \ud544\uc694\ud568\\n\\n- `<nexus_dir>/system/org/sonatype/nexus/plugins/nexus-repository-r/1.0.4/nexus-repository-r-1.0.4.jar`\\n- `<nexus_dir>/system/com/sonatype/nexus/assemblies/nexus-oss-feature/3.x.y/nexus-oss-feature-3.x.y-features.xml`\\n- `<nexus_dir>/system/com/sonatype/nexus/assemblies/nexus-pro-feature/3.x.y/nexus-pro-feature-3.x.y-features.xml`\\n\\n```xml\\n      <feature version=\\"3.x.y.xy\\" prerequisite=\\"false\\" dependency=\\"false\\">nexus-repository-rubygems</feature>\\n+     <feature version=\\"1.0.4\\" prerequisite=\\"false\\" dependency=\\"false\\">nexus-repository-r</feature>\\n      <feature version=\\"3.x.y.xy\\" prerequisite=\\"false\\" dependency=\\"false\\">nexus-repository-yum</feature>\\n  </feature>\\n```\\n\\n\uadf8\ub9ac\uace0,\\n\\n```xml\\n+ <feature name=\\"nexus-repository-r\\" description=\\"org.sonatype.nexus.plugins:nexus-repository-r\\" version=\\"1.0.3\\">\\n+     <details>org.sonatype.nexus.plugins:nexus-repository-r</details>\\n+     <bundle>mvn:org.sonatype.nexus.plugins/nexus-repository-r/1.0.4</bundle>\\n+ </feature>\\n </features>\\n```\\n\\n### 6-3. nexus repository \ucd94\uac00\\n\\n- \uc815\uc0c1\uc801\uc73c\ub85c \uc124\uce58\ub418\uba74 nexus\uc758 create repository \uba54\ub274\uc5d0 r(proxy), r(hosted), r(group) \uba54\ub274\uac00 \ud45c\uc2dc\ub428\\n- r(proxy),r(hosted) repository\ub97c \ucd94\uac00 \ud6c4 r(group)\uc73c\ub85c \ubb36\uc5b4\uc11c repository \uc0dd\uc131.\\n  \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \ub9c1\ud06c \ucc38\uc870\\n  [nexus R repository \ub9cc\ub4e4\uae30](https://github.com/sonatype-nexus-community/nexus-repository-r/blob/master/docs/R_USER_DOCUMENTATION.md)\\n\\n### 6-4. \ub85c\uceec R \uc124\uc815\\n\\n- R-cran\uc744 proxy \ub97c \uac70\uccd0\uac00\ub3c4\ub85d repo list \uc124\uc815\uc774 \ud544\uc694\\n\\n```sh\\n# OS \ubcc4 \uc704\uce58 \uc0c1\uc774 R home \uba85\ub839\uc5b4\ub85c \ud655\uc778\\n#\u2018/Library/Frameworks/R.framework/Resources/etc/\u2019 on OS X,\\n#\u2018C:Program FilesRR-***etc\u2019 on Windows,\\n#\u2018/etc/R/\u2019 on Debian.\\nR> R.home(component = \\"home\\") # 1st config. filename Rprofile.site\\nR> path.expand(\\"~\\") # 2nd config. filename .Rprofile\\n\\n# edit $HOME/etc/\\n## Default repo <\u2014 Rprofile.site\\nlocal({r <- getOption(\\"repos\\")\\n       r[\\"Nexus\\"] <- \\"http://<nexusID>:<nexusPW>@<nexus r(group repository) address>\\"\\n       options(repos=r)\\n})\\n```\\n\\nR \uc2e0\uaddc \uc138\uc158 \uc5f0\uacb0 \ud6c4 \ud655\uc778\\n\\n```R\\nR> getOption(\'repos\')\\n----------------------------------------------------------------\\n                                                    Nexus\\n\\"http://<nexusID>:<nexusPW>@<nexus r(group repository) address>\\"\\n----------------------------------------------------------------\\nR>\\n```\\n\\n### 6-5. R package download test\\n\\n```R\\n> remove.packages(\'dplyr\')\\nRemoving package from \u2018/Library/Frameworks/R.framework/Versions/3.5/Resources/library\u2019\\n(as \u2018lib\u2019 is unspecified)\\nError in remove.packages : there is no package called \u2018dplyr\u2019\\n> library(dplyr)\\nError in library(dplyr) : there is no package called \u2018dplyr\u2019\\n> getOption(\'repos\')\\n                                                    Nexus\\n\\"http://<nexusID>:<nexusPW>@<nexus r(group repository) address>\\"\\n> install.packages(\'dplyr\')\\ntrying URL \'http://<nexusID>:<nexusPW>@<nexus r(group repository) address>/bin/macosx/el-capitan/contrib/3.5/dplyr_0.8.3.tgz\'\\nContent type \'application/x-tgz\' length 6265040 bytes (6.0 MB)\\n==================================================\\ndownloaded 6.0 MB\\n\\n\\nThe downloaded binary packages are in\\n\\t/var/folders/98/5jh6pvh54_n1xqk_y7c66t580000gn/T//Rtmpxy9PGN/downloaded_packages\\n> library(dplyr)\\n\\nAttaching package: \u2018dplyr\u2019\\n\\nThe following objects are masked from \u2018package:stats\u2019:\\n\\n    filter, lag\\n\\nThe following objects are masked from \u2018package:base\u2019:\\n\\n    intersect, setdiff, setequal, union\\n\\n>\\n```\\n\\n### 6-6. R package upload test\\n\\n- upload\ub294 curl \ub4f1\uc73c\ub85c \uc9c4\ud589\\n\\n```sh\\n## package\uc758 DESCRIPTION version\uacfc \ud30c\uc77c \uba85\uc758 version \uc774 \uc77c\uce58\ud574\uc57c \ud568\\ncurl -v --user \'<nexusID>:<nexsusPW>\' --upload-file userPackage.tar.gz http://localhost:8081/repository/r-snap/src/contrib/userPackage_0.1.0.tar.gz\\n```\\n\\n```R\\n##\\n> install.packages(\'userPackage\')\\n\uc624\ub85c\uc9c0 \uc18c\uc2a4\ud615\ud0dc\ub85c\ub9cc \uc81c\uacf5\ub418\ub294 \ud328\ud0a4\uc9c0\uc774\ubbc0\ub85c C/C++/Fortran\uc73c\ub85c \uc791\uc131\ub41c\\n  \ucf54\ub4dc\ub4e4\uc5d0 \ub300\ud55c \ucef4\ud30c\uc77c\uc774 \ud544\uc694\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.: \u2018userPackage\u2019\\nDo you want to attempt to install these from sources? (Yes/no/cancel) Yes\\n\uc18c\uc2a4\ud615\ud0dc\uc758 \ud328\ud0a4\uc9c0 \u2018userPackage\u2019(\ub4e4)\ub97c \uc124\uce58\ud569\ub2c8\ub2e4.\\n\\nURL \'http://<nexusID>:<nexusPW>@<nexus r(group repository) address>/src/contrib/userPackage_0.1.0.tar.gz\'\uc744 \uc2dc\ub3c4\ud569\ub2c8\ub2e4\\nContent type \'application/x-gzip\' length 17215032 bytes (16.4 MB)\\n==================================================\\ndownloaded 16.4 MB\\n\\n* installing *source* package \u2018userPackage\u2019 ...\\n** R\\n** inst\\n** byte-compile and prepare package for lazy loading\\n** help\\n*** installing help indices\\n** building package indices\\n** testing if installed package can be loaded\\n* DONE (userPackage)\\n\\n\ub2e4\uc6b4\ub85c\ub4dc\ud55c \uc18c\uc2a4 \ud328\ud0a4\uc9c0\ub4e4\uc740 \ub2e4\uc74c\uc758 \uc704\uce58\uc5d0 \uc788\uc2b5\ub2c8\ub2e4\\n        \u2018/private/var/folders/98/5jh6pvh54_n1xqk_y7c66t580000gn/T/RtmppazSJ3/downloaded_packages\u2019\\n```\\n\\n\ud639\uc740\\n\\n```r\\ninstall.packages(\'userPackage\',repos=\\"http://<nexusID>:<nexusPW>@<nexus r(group repository) address>\\");\\n```\\n\\n### 6-7. \ucc38\uace0 \uc0ac\uc774\ud2b8\\n\\n1. [r-plugin github site](https://github.com/sonatype-nexus-community/nexus-repository-r)\\n2. [nexus \uc124\uc815 \ubc29\ubc95](https://github.com/sonatype-nexus-community/nexus-repository-r/blob/master/docs/R_USER_DOCUMENTATION.md)\\n3. [Rprofile \uc124\uc815 \ubc29\ubc95](https://www.r-bloggers.com/fun-with-rprofile-and-customizing-r-startup/)"},{"id":"/2020/01/30/third-blog","metadata":{"permalink":"/2020/01/30/third-blog","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-01-30-third-blog.md","source":"@site/blog/2020-01-30-third-blog.md","title":"Set up project dev environments","description":"summary","date":"2019-01-29T00:16:01.000Z","tags":[{"inline":true,"label":"dev","permalink":"/tags/dev"}],"readingTime":8.615,"hasTruncateMarker":true,"authors":[{"name":"Hanbyul Cho","title":"Engineer","url":"https://github.com/hansgun","page":{"permalink":"/authors/hansgun"},"socials":{"linkedin":"https://www.linkedin.com/in/hanbyulcho1/","github":"https://github.com/hansgun"},"imageURL":"https://github.com/hansgun.png","key":"hansgun"}],"frontMatter":{"layout":"post","title":"Set up project dev environments","date":"2019-01-29 00:16:01 -0600","tags":["dev"],"toc":true,"toc_label":"On This Page","toc_icon":"cog","toc_position":"sticky","authors":["hansgun"]},"unlisted":false,"prevItem":{"title":"Setup CI/CD [Jenkins+Nexus for Spring, Docker, R]","permalink":"/2019/11/17/first-blog"}},"content":"> summary\\n\x3c!-- truncate --\x3e\\n\\n# 1. [Project] \uac1c\ubc1c \ud658\uacbd \uc124\uc815\\n\\n---\\n\\n> \ud504\ub85c\uc81d\ud2b8 \uc218\ud589 \uacb0\uacfc\ub85c \ubbfc\uac10\ud55c \uc815\ubcf4\ub294 [] \ud639\uc740 `<>` \uc73c\ub85c \ub0b4\uc6a9\uc744 \ub300\uce58\ud568\\n\\n---\\n\\n## 1.1 Host Naming Convention\\n\\n`[Project]-<flag><node-number>[-<env>].io`\\n\\n`<flag>`:\\n\\n- s: Service Node.\\n- t: Streaming Node.\\n- g: Gateway Node.\\n\\n`<node-number>`: Node Numbering \uc73c\ub85c \uc608\ub97c\ub4e4\uc5b4, \'01\', \'02\',etc.\\n\\n`<env>`: Deploy \ud658\uacbd\uc73c\ub85c, \uc608\ub97c\ub4e4\uc5b4, \uac1c\ubc1c \ud658\uacbd\uc77c \uacbd\uc6b0, \'dev\'. \uc0c1\uc6a9 \ud658\uacbd\uc740 \uc5c6\uc74c.\\n\\n## 1.2 Hosts File \ub4f1\ub85d\\n\\nLocal \uac1c\ubc1c Machine \uc758 hosts file \uc5d0 \ub2e4\uc74c\uacfc \uac19\uc774 \ub4f1\ub85d\ud569\ub2c8\ub2e4:\\n\\n```bash\\n<\uc11c\ubc84IP>    [Project]-s01-dev    [Project]-s01-dev.<full_name>\\n```\\n\\n## 1.3 \uac1c\ubc1c Server \uc811\uc18d\\n\\n\uac1c\ubc1c Server \uc811\uc18d \ubc29\ubc95\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\\n\\n```bash\\nssh -i <aws-pem> cento-s01-dev.io\\n```\\n\\n\uc811\uc18d\ud6c4 \uc0ac\uc6a9\uc790\ub97c `<UserID>` \ub85c \uc804\ud658\ud569\ub2c8\ub2e4:\\n\\n```bash\\nsudo su - <UserID>;\\n```\\n\\n## 1.4 \uc124\uce58\ub41c Components\\n\\n\uac1c\ubc1c Server \uc5d0 \uc124\uce58\ub41c \uc911\uc694 Component \ub4e4\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\\n\\n- JDK 1.8\\n- Maven 3.x\\n- Docker\\n- Redis\\n- PostgreSQL\\n\\n## 1.5 PostgreSQL DB \uc5f0\uacb0\\n\\nPostgreSQL Client \ub85c PostgreSQL Server \uc5d0 \ub2e4\uc74c\uacfc \uac19\uc774 \uc5f0\uacb0\ud560\uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\nAirflow DB:\\n\\n```bash\\npsql -h[Project]-s01-dev  -p 5432 -U airflow -W -d airflow;\\n```\\n\\nUser sample DB:\\n\\n```bash\\npsql -h[Project]-s01-dev -p 5432 -U <userschema> -W -d <userDB_name>;\\n```\\n```\\n~~## 1.6 Airflow Components ( Old Version. See 1.7 section)~~\\n\\n~~\uc124\uce58\ub41c Airflow Component \ub4e4\uc740 Docker Container \ub85c\uc11c \uc2e4\ud589\ub418\uace0 \uc788\uc2b5\ub2c8\ub2e4.~~\\n\\n~~\uc124\uce58\ub41c Airflow Component \ub4e4\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.~~\\n\\n~~WebServer: [http:<\uc11c\ubc84IP>:8080]~~\\n~~Worker~~\\n~~Scheduler~~\\n~~Flower: [http:<\uc11c\ubc84IP>:5555]~~\\n\\n### ~~1.6.1 Airflow Docker \uc124\uce58 \ubc29\ubc95 v.1 (Old Version.)~~\\n\\n~~Docker Container \ud615\ud0dc\ub85c Airflow \ub97c \uc124\uce58\ud558\ub294 \ubc29\ubc95\uc744 \uc124\uba85\ud558\uaca0\uc2b5\ub2c8\ub2e4.~~\\n```\\n\\n```bash\\n# add user to docker group.\\nsudo su <userID>;\\nsudo usermod -aG docker $(whoami);\\n\\n# airflow docker build.\\n## NOTE: docker airflow is originated from https://github.com/puckel/docker-airflow\\n\\ngit clone https://github.com/[Project].git;\\ncd [Project];\\ngit fetch origin;\\ngit checkout dev;\\ncd workflow/docker-airflow;\\n\\n------ R \uad00\ub828 \ucd94\uac00 \uc0ac\ud56d\\n# R\uc774 \ud3ec\ud568\ub41c \uc774\ubbf8\uc9c0\ub294 workflow/docker-airflow/docker_with_R \uc5d0 \uc788\uc74c..\\n# customized R package tar \uc0dd\uc131\\ncd workflow/docker-airflow/docker_with_R\\nsh make_skytale_tar.sh\\ndocker build --rm -t <project_name>/docker-airflow-withR .\\n# \uc544\ub798\uc758 docker build \uc0dd\ub7b5\\n------- R \uad00\ub828 \ucd94\uac00 \uc0ac\ud56d(\ub05d)\\n\\ndocker build --rm -t <project_name>/docker-airflow .\\n\\n# create directories for volumes:\\nsudo mkdir -p /data01/airflow/docker-airflow-volumes;\\nsudo mkdir -p /data01/airflow/docker-airflow-volumes/{logs,plugins,dags};\\nsudo chmod 777 -R /data01/airflow/docker-airflow-volumes;\\n\\n# add python deps into requirements.txt.\\nsudo vi /data01/airflow/docker-airflow-volumes/requirements.txt;\\nFlask==1.0.4\\npsycopg2-binary\\n\\n# install rest api plugin to the directory of plugins volume.\\nwget https://github.com/teamclairvoyant/airflow-rest-api-plugin/archive/v1.0.5.tar.gz\\n\\n## copy all the files to \'/data01/airflow/docker-airflow-volumes/plugins\' dir.\\n\\n\\nsudo su <userID>;\\n## webserver, worker ::: -e LD_LIBRARY_PATH=/usr/lib/jvm/java-11-openjdk-amd64/lib/server/ \\\\ \ucd94\uac00\\n# Dockerfile \uc790\uccb4\uc5d0 JAVA_HOME \ucd94\uac00\ud574\uc11c \ud558\ub294 \ubc29\ubc95 \ud655\uc778 \ud544\uc694\\n# run airflow webserver.\\ndocker run -d \\\\\\n    --add-host <\uc11c\ubc84\uc774\ub984>:<\uc11c\ubc84IP> \\\\\\n    -v /data01/airflow/docker-airflow-volumes/plugins/:/usr/local/airflow/plugins \\\\\\n    -v /data01/airflow/docker-airflow-volumes/dags/:/usr/local/airflow/dags \\\\\\n    -v /data01/airflow/docker-airflow-volumes/logs/:/usr/local/airflow/logs \\\\\\n    -v /data01/airflow/docker-airflow-volumes/requirements.txt:/requirements.txt \\\\\\n    -v /data01/airflow/docker-airflow-volumes/temp/:/usr/local/airflow/temp \\\\\\n    -e REDIS_HOST <\uc11c\ubc84IP> \\\\\\n    -e POSTGRES_HOST <\uc11c\ubc84IP> \\\\\\n    -e POSTGRES_USER=airflow \\\\\\n    -e POSTGRES_PASSWORD=<password> \\\\\\n    -e POSTGRES_DB=airflow \\\\\\n    -e AIRFLOW__CORE__EXECUTOR=CeleryExecutor \\\\\\n    -e AIRFLOW__CORE__SQL_ALCHEMY_CONN=\\"postgresql+psycopg2://airflow:<password> <\uc11c\ubc84IP>:5432/airflow\\" \\\\\\n        -e AIRFLOW__CELERY__RESULT_BACKEND=\\"db+postgresql://airflow:<password> <\uc11c\ubc84IP>:5432/airflow\\" \\\\\\n    -e AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False \\\\\\n    -e AIRFLOW__CORE__DEFAULT_TIMEZONE=Asia/Seoul \\\\\\n    -e LD_LIBRARY_PATH=/usr/lib/jvm/java-11-openjdk-amd64/lib/server/ \\\\\\n    -v /etc/localtime:/etc/localtime:ro \\\\\\n    -e TZ=Asia/Seoul \\\\\\n    -p 8080:8080 \\\\\\n    --name airflow-webserver \\\\\\n    <project_name>/docker-airflow webserver\\n\\n\\n# view docker logs: airflow webserver.\\ndocker logs -f airflow-webserver;\\n\\n\\n# run airflow worker.\\ndocker run -d \\\\\\n    --add-hosT <\uc11c\ubc84\uc774\ub984>:<\uc11c\ubc84IP> \\\\\\n    -v /data01/airflow/docker-airflow-volumes/plugins/:/usr/local/airflow/plugins \\\\\\n    -v /data01/airflow/docker-airflow-volumes/dags/:/usr/local/airflow/dags \\\\\\n    -v /data01/airflow/docker-airflow-volumes/logs/:/usr/local/airflow/logs \\\\\\n    -v /data01/airflow/docker-airflow-volumes/requirements.txt:/requirements.txt \\\\\\n    -v /data01/airflow/docker-airflow-volumes/temp/:/usr/local/airflow/temp \\\\\\n    -e REDIS_HOST <\uc11c\ubc84IP> \\\\\\n    -e POSTGRES_HOST <\uc11c\ubc84IP> \\\\\\n    -e POSTGRES_USER=airflow \\\\\\n    -e POSTGRES_PASSWORD=<password> \\\\\\n    -e POSTGRES_DB=airflow \\\\\\n    -e AIRFLOW__CORE__EXECUTOR=CeleryExecutor \\\\\\n    -e AIRFLOW__CORE__SQL_ALCHEMY_CONN=\\"postgresql+psycopg2://airflow:<password> <\uc11c\ubc84IP>:5432/airflow\\" \\\\\\n        -e AIRFLOW__CELERY__RESULT_BACKEND=\\"db+postgresql://airflow:<password> <\uc11c\ubc84IP>:5432/airflow\\" \\\\\\n    -e AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False \\\\\\n    -e AIRFLOW__CORE__DEFAULT_TIMEZONE=Asia/Seoul \\\\\\n    -e LD_LIBRARY_PATH=/usr/lib/jvm/java-11-openjdk-amd64/lib/server/ \\\\\\n    -v /etc/localtime:/etc/localtime:ro \\\\\\n    -e TZ=Asia/Seoul \\\\\\n    -p 8793:8793 \\\\\\n    --name airflow-worker \\\\\\n    <project_name>/docker-airflow worker\\n\\n\\n# view docker logs: airflow worker.\\ndocker logs -f airflow-worker;\\n\\n\\n# run airflow scheduler.\\ndocker run -d \\\\\\n    --add-host <\uc11c\ubc84\uc774\ub984>:<\uc11c\ubc84IP> \\\\\\n    -v /data01/airflow/docker-airflow-volumes/plugins/:/usr/local/airflow/plugins \\\\\\n    -v /data01/airflow/docker-airflow-volumes/dags/:/usr/local/airflow/dags \\\\\\n    -v /data01/airflow/docker-airflow-volumes/logs/:/usr/local/airflow/logs \\\\\\n    -v /data01/airflow/docker-airflow-volumes/requirements.txt:/requirements.txt \\\\\\n    -v /data01/airflow/docker-airflow-volumes/temp/:/usr/local/airflow/temp \\\\\\n    -e REDIS_HOST=<\uc11c\ubc84IP> \\\\\\n    -e POSTGRES_HOST=<\uc11c\ubc84IP> \\\\\\n    -e POSTGRES_USER=airflow \\\\\\n    -e POSTGRES_PASSWORD=<password> \\\\\\n    -e POSTGRES_DB=airflow \\\\\\n        -e AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=2 \\\\\\n    -e AIRFLOW__CORE__EXECUTOR=CeleryExecutor \\\\\\n    -e AIRFLOW__CORE__SQL_ALCHEMY_CONN=\\"postgresql+psycopg2://airflow:<password>@<\uc11c\ubc84IP>:5432/airflow\\" \\\\\\n        -e AIRFLOW__CELERY__RESULT_BACKEND=\\"db+postgresql://airflow:<password>@<\uc11c\ubc84IP>:5432/airflow\\" \\\\\\n    -e AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False \\\\\\n    -e AIRFLOW__CORE__DEFAULT_TIMEZONE=Asia/Seoul \\\\\\n    -v /etc/localtime:/etc/localtime:ro \\\\\\n    -e TZ=Asia/Seoul \\\\\\n    --name airflow-scheduler \\\\\\n    <project_name>/docker-airflow scheduler\\n\\n\\n# view docker logs: airflow scheduler.\\ndocker logs -f airflow-scheduler;\\n\\n\\n# run airflow flower.\\ndocker run -d \\\\\\n    --add-host <\uc11c\ubc84\uc774\ub984>:<\uc11c\ubc84IP> \\\\\\n    -v /data01/airflow/docker-airflow-volumes/plugins/:/usr/local/airflow/plugins \\\\\\n    -v /data01/airflow/docker-airflow-volumes/dags/:/usr/local/airflow/dags \\\\\\n    -v /data01/airflow/docker-airflow-volumes/logs/:/usr/local/airflow/logs \\\\\\n    -v /data01/airflow/docker-airflow-volumes/requirements.txt:/requirements.txt \\\\\\n    -v /data01/airflow/docker-airflow-volumes/temp/:/usr/local/airflow/temp \\\\\\n    -e REDIS_HOST=<\uc11c\ubc84IP> \\\\\\n    -e POSTGRES_HOST=<\uc11c\ubc84IP> \\\\\\n    -e POSTGRES_USER=airflow \\\\\\n    -e POSTGRES_PASSWORD=<password> \\\\\\n    -e POSTGRES_DB=airflow \\\\\\n    -e AIRFLOW__CORE__EXECUTOR=CeleryExecutor \\\\\\n    -e AIRFLOW__CORE__SQL_ALCHEMY_CONN=\\"postgresql+psycopg2://airflow:<password>@<\uc11c\ubc84IP>:5432/airflow\\" \\\\\\n        -e AIRFLOW__CELERY__RESULT_BACKEND=\\"db+postgresql://airflow:<password>@<\uc11c\ubc84IP>:5432/airflow\\" \\\\\\n    -e AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False \\\\\\n    -e AIRFLOW__CORE__DEFAULT_TIMEZONE=Asia/Seoul \\\\\\n    -v /etc/localtime:/etc/localtime:ro \\\\\\n    -e TZ=Asia/Seoul \\\\\\n    -p 5555:5555 \\\\\\n    --name airflow-flower \\\\\\n    <project_name>/docker-airflow flower\\n\\n\\n# view docker logs: airflow flower.\\ndocker logs -f airflow-flower;\\n\\n\\n# check rest api.\\ncurl --header \\"rest_api_plugin_http_token: changeme\\" http://<\uc11c\ubc84IP>:8080/admin/rest_api/api?api=version\\n\\n# deploy dag.\\ncurl -X POST --header \\"rest_api_plugin_http_token: changeme\\" -H \'Content-Type: multipart/form-data\' -F \'dag_file=@<project_name>-test-dag8.py\' -F \'force=on\' http://<\uc11c\ubc84IP>:8080/admin/rest_api/api?api=deploy_dag\\n\\n# trigger dag.\\ncurl --header \\"rest_api_plugin_http_token: changeme\\" http://<\uc11c\ubc84IP>:8080/admin/rest_api/api?api=trigger_dag&dag_id=tutorial-<project_name>7\\n```\\n\\n\\n## 1.7 Airflow Docker \uc124\uce58 \ubc29\ubc95 v.2 (using docker-compose)\\n\\n- docker compose\ub97c \ud1b5\ud558\uc5ec component dependency\ub97c \uace0\ub824\ud558\uc5ec single command\ub85c \uc2e4\ud589\\n- \uc2e4\uc81c \uc218\ud589 \ub0b4\uc6a9\uc740 v.1 \uacfc \ub3d9\uc77c.\\n\\n### 1.7.1 \uc124\uce58\uacfc\uc815\\n\\n\ud30c\uc77c \uc704\uce58 : `[Project]/workflow/docker-airflow` \\n\uad00\ub828 \ud30c\uc77c :\\n\\n- `docker-compose.yml`\\n- `.env` [ .env\ub294 \ud604\uc7ac local \uc124\uc815, \uac1c\ubc1c\uae30\uc5d0\uc11c\ub294 .env_dev\uc640 \uad50\uccb4 \ud544\uc694.. ]\\n- \uc2e4\ud589 \uba85\ub839 : `docker-compose -p [Project] up -d --build` \uc2e4\ud589 \uc2dc container\uc774\ub984\uc740 `[Project]_<container \uc774\ub984>_<\uc778\uc2a4\ud134\uc2a4 \ubc88\ud638>` \ud615\ud0dc\\n\\n`.env` \ud30c\uc77c \ub0b4\uc6a9 : \ud658\uacbd\uc5d0 \ub9de\uac8c \ubcc0\uacbd \ud544\uc694\\n\\n```\\n###### section 1. postgre\\nPOSTGRES_HOST=192.168.3.108\\necho ${POSTGRES_HOST}\\nPOSTGRES_USER=airflow\\nPOSTGRES_PASSWORD=***** # \uc2e4\uc81c \ud328\uc2a4\uc6cc\ub4dc\\n\\n###### section 2. redis\\nREDIS_HOST=192.168.3.108\\n\\n###### section 3. APP\\nAPP_HOST_NAME=[Project]-app.name\\nAPP_HOST_IP=192.168.3.108\\nAPP_VOLUMN_DIR=/Users/han/data01/airflow/docker-airflowvolumns\\n\\n```\\n\\n`docker-compose.yml` \ud30c\uc77c \ub0b4\uc6a9 (\uc8fc\uc11d \ub0b4\uc6a9\uc740 \ud604\uc7ac \ud658\uacbd\uc5d0 \uc774\ubbf8 \uc124\uce58\ub418\uc5b4 \uc788\ub2e4\uace0 \uac00\uc815\ud558\uc600\uc744 \ub54c)\\n\\n```yaml\\nversion: \'2.1\'\\n\\n services:\\n #  postgre:\\n #    image: postgres:10.10\\n #    environment:\\n #      - POSTGRES_DB=airflow\\n #      - POSTGRES_USER=${POSTGRES_USER}\\n #      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\\n #      - POSTGRES_INITDB_ARGS=--encoding=UTF-8\\n #    ports:\\n #      - \\"5432:5432\\"\\n #    healthcheck:\\n #      test: \\"pg_isready -h localhost -p 5432 -q -U postgres\\"\\n #      interval: 3s\\n #      timeout: 1s\\n #      retries: 10\\n #\\n #  redis:\\n #    image: redis:3.2.12\\n #    ports:\\n #      - \\"6379:6379\\"\\n   airflow-webserver:\\n     build:\\n       context: .\\n     command: webserver\\n     environment:\\n       - REDIS_HOST=${APP_HOST_NAME}\\n       - POSTGRES_HOST=${POSTGRES_HOST}\\n       - POSTGRES_USER=${POSTGRES_USER}\\n       - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\\n       - POSTGRES_DB=airflow\\n       - AIRFLOW__CORE__EXECUTOR=CeleryExecutor\\n       - AIRFLOW__CORE__SQL_ALCHEMY_CONN=\\"postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/airflow\\"\\n       - AIRFLOW__CELERY__RESULT_BACKEND=\\"db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/airflow\\"\\n       - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False\\n       - AIRFLOW__CORE__DEFAULT_TIMEZONE=Asia/Seoul\\n       - TZ=Asia/Seoul\\n     extra_hosts:\\n       - ${APP_HOST_NAME}:${APP_HOST_IP}\\n     volumes:\\n       - ${APP_VOLUMN_DIR}/plugins/:/usr/local/airflow/plugins\\n       - ${APP_VOLUMN_DIR}/dags/:/usr/local/airflow/dags\\n       - ${APP_VOLUMN_DIR}/logs/:/usr/local/airflow/logs\\n         #- ${APP_VOLUMN_DIR}/requirements.txt:/requirements.txt\\n       - ${APP_VOLUMN_DIR}/temp/:/usr/local/airflow/temp\\n       - /etc/localtime:/etc/localtime:ro\\n     ports:\\n       - \\"8080:8080\\"\\n         #depends_on:\\n         #- postgre\\n         #- redis\\n\\n   airflow-scheduler:\\n     build:\\n       context: .\\n     command: scheduler\\n     environment:\\n       - REDIS_HOST=${APP_HOST_NAME}\\n       - POSTGRES_HOST=${POSTGRES_HOST}\\n       - POSTGRES_USER=${POSTGRES_USER}\\n       - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\\n       - POSTGRES_DB=airflow\\n       - AIRFLOW__CORE__EXECUTOR=CeleryExecutor\\n       - AIRFLOW__CORE__SQL_ALCHEMY_CONN=\\"postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/airflow\\"\\n       - AIRFLOW__CELERY__RESULT_BACKEND=\\"db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/airflow\\"\\n       - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False\\n       - AIRFLOW__CORE__DEFAULT_TIMEZONE=Asia/Seoul\\n       - TZ=Asia/Seoul\\n     extra_hosts:\\n       - ${APP_HOST_NAME}:${APP_HOST_IP}\\n     volumes:\\n       - ${APP_VOLUMN_DIR}/plugins/:/usr/local/airflow/plugins\\n       - ${APP_VOLUMN_DIR}/dags/:/usr/local/airflow/dags\\n       - ${APP_VOLUMN_DIR}/logs/:/usr/local/airflow/logs\\n         #- ${APP_VOLUMN_DIR}/requirements.txt:/requirements.txt\\n       - ${APP_VOLUMN_DIR}/temp/:/usr/local/airflow/temp\\n       - /etc/localtime:/etc/localtime:ro\\n     depends_on:\\n       - airflow-webserver\\n\\n\\n   airflow-flower:\\n     build:\\n       context: .\\n     command: flower\\n     environment:\\n       - REDIS_HOST=${APP_HOST_NAME}\\n       - POSTGRES_HOST=${POSTGRES_HOST}\\n       - POSTGRES_USER=${POSTGRES_USER}\\n       - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\\n       - POSTGRES_DB=airflow\\n       - AIRFLOW__CORE__EXECUTOR=CeleryExecutor\\n       - AIRFLOW__CORE__SQL_ALCHEMY_CONN=\\"postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/airflow\\"\\n       - AIRFLOW__CELERY__RESULT_BACKEND=\\"db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/airflow\\"\\n       - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False\\n       - AIRFLOW__CORE__DEFAULT_TIMEZONE=Asia/Seoul\\n       - TZ=Asia/Seoul\\n     extra_hosts:\\n       - ${APP_HOST_NAME}:${APP_HOST_IP}\\n     volumes:\\n       - ${APP_VOLUMN_DIR}/plugins/:/usr/local/airflow/plugins\\n       - ${APP_VOLUMN_DIR}/dags/:/usr/local/airflow/dags\\n       - ${APP_VOLUMN_DIR}/logs/:/usr/local/airflow/logs\\n         #- ${APP_VOLUMN_DIR}/requirements.txt:/requirements.txt\\n       - ${APP_VOLUMN_DIR}/temp/:/usr/local/airflow/temp\\n       - /etc/localtime:/etc/localtime:ro\\n     ports:\\n       - \\"5555:5555\\"\\n         #depends_on:\\n         #- redis\\n\\n   airflow-worker:\\n     build:\\n       context: ./docker_with_R/\\n     command: worker\\n     environment:\\n       - REDIS_HOST=${APP_HOST_NAME}\\n       - POSTGRES_HOST=${POSTGRES_HOST}\\n       - POSTGRES_USER=${POSTGRES_USER}\\n       - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\\n       - POSTGRES_DB=airflow\\n       - AIRFLOW__CORE__EXECUTOR=CeleryExecutor\\n       - AIRFLOW__CORE__SQL_ALCHEMY_CONN=\\"postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/airflow\\"\\n       - AIRFLOW__CELERY__RESULT_BACKEND=\\"db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/airflow\\"\\n       - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False\\n       - AIRFLOW__CORE__DEFAULT_TIMEZONE=Asia/Seoul\\n       - TZ=Asia/Seoul\\n     extra_hosts:\\n       - ${APP_HOST_NAME}:${APP_HOST_IP}\\n     volumes:\\n       - ${APP_VOLUMN_DIR}/plugins/:/usr/local/airflow/plugins\\n       - ${APP_VOLUMN_DIR}/dags/:/usr/local/airflow/dags\\n       - ${APP_VOLUMN_DIR}/logs/:/usr/local/airflow/logs\\n         #- ${APP_VOLUMN_DIR}/requirements.txt:/requirements.txt\\n       - ${APP_VOLUMN_DIR}/temp/:/usr/local/airflow/temp\\n       - /etc/localtime:/etc/localtime:ro\\n     ports:\\n       - \\"8793:8793\\"\\n     depends_on:\\n       - airflow-scheduler\\n```\\n\\n\\n### 1.7.2 \uc2e4\ud589\uacb0\uacfc\\n\\n```bash\\n> docker-compose -p [Project] up -d\\nRemoving [Project]_airflow-webserver_1\\nRecreating [Project]_airflow-flower_1                 ... done\\nRecreating b415085d2612_[Project]_airflow-webserver_1 ... done\\nCreating [Project]_airflow-scheduler_1                ... done\\nCreating [Project]_airflow-worker_1                   ... done\\n> docker ps\\nCONTAINER ID        IMAGE                      COMMAND                  CREATED             STATUS              PORTS                                            NAMES\\n3a82d6c17ee0        [Project]_airflow-worker      \\"/entrypoint.sh work\u2026\\"   5 seconds ago       Up 4 seconds        5555/tcp, 8080/tcp, 0.0.0.0:8793->8793/tcp       [Project]_airflow-worker_1\\n87e87e660969        [Project]_airflow-scheduler   \\"/entrypoint.sh sche\u2026\\"   6 seconds ago       Up 5 seconds        5555/tcp, 8080/tcp, 8793/tcp                     [Project]_airflow-scheduler_1\\nc70230f8b1d3        [Project]_airflow-flower      \\"/entrypoint.sh flow\u2026\\"   7 seconds ago       Up 6 seconds        8080/tcp, 0.0.0.0:5555->5555/tcp, 8793/tcp       [Project]_airflow-flower_1\\nc726e9fdfbc2        [Project]_airflow-webserver   \\"/entrypoint.sh webs\u2026\\"   7 seconds ago       Up 6 seconds        5555/tcp, 8793/tcp, 0.0.0.0:8080->8080/tcp       [Project]_airflow-webserver_1\\n>\\n\\n```\\n\\n### 1.7.3 scale-out test\\n\\n```bash\\n> docker ps                                                                                                                        CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                        NAMES\\n32b99476f0ab        airflow_worker      \\"/entrypoint.sh work\u2026\\"   26 seconds ago      Up 26 seconds       5555/tcp, 8080/tcp, 8793/tcp                 airflow_worker_1\\nac788e72dd21        airflow_scheduler   \\"/entrypoint.sh sche\u2026\\"   27 seconds ago      Up 27 seconds       5555/tcp, 8080/tcp, 8793/tcp                 airflow_scheduler_1\\n0cb6456b4869        airflow_flower      \\"/entrypoint.sh flow\u2026\\"   29 seconds ago      Up 27 seconds       8080/tcp, 0.0.0.0:5555->5555/tcp, 8793/tcp   airflow_flower_1\\n4483b48d0078        airflow_webserver   \\"/entrypoint.sh webs\u2026\\"   29 seconds ago      Up 28 seconds       5555/tcp, 8793/tcp, 0.0.0.0:8080->8080/tcp   airflow_webserver_1\\n> docker-compose -p airflow scale worker=2\\nWARNING: The scale command is deprecated. Use the up command with the --scale flag instead.\\nStarting airflow_worker_1 ... done\\nCreating airflow_worker_2 ... done\\n> docker ps\\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                        NAMES\\n71e9fce448f2        airflow_worker      \\"/entrypoint.sh work\u2026\\"   4 seconds ago       Up 2 seconds        5555/tcp, 8080/tcp, 8793/tcp                 airflow_worker_2\\n32b99476f0ab        airflow_worker      \\"/entrypoint.sh work\u2026\\"   44 seconds ago      Up 43 seconds       5555/tcp, 8080/tcp, 8793/tcp                 airflow_worker_1\\nac788e72dd21        airflow_scheduler   \\"/entrypoint.sh sche\u2026\\"   45 seconds ago      Up 44 seconds       5555/tcp, 8080/tcp, 8793/tcp                 airflow_scheduler_1\\n0cb6456b4869        airflow_flower      \\"/entrypoint.sh flow\u2026\\"   47 seconds ago      Up 45 seconds       8080/tcp, 0.0.0.0:5555->5555/tcp, 8793/tcp   airflow_flower_1\\n4483b48d0078        airflow_webserver   \\"/entrypoint.sh webs\u2026\\"   47 seconds ago      Up 45 seconds       5555/tcp, 8793/tcp, 0.0.0.0:8080->8080/tcp   airflow_webserver_1\\n>\\n```\\n\\n## 1.8 R Package \uc124\uce58 \ubc29\ubc95\\n\\n```bash\\ncd ${[Project]_ROOT_DIR}/workflow/job-runner/skytale\\n\\nR -e \\"install.packages(\'devtools\', repos=\'https://cloud.r-project.org\'); library(devtools); devtools::install(\'./\')\\"\\n```"}]}}')}}]);